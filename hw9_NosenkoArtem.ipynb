{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NosenkoArtem/Categorical-Encoding/blob/master/hw9_NosenkoArtem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ZjF3yqwgO8"
      },
      "source": [
        "Цель данного домашнего задания — познакомить вас с концепцией и реализацией RAG в LLM, а также развить навыки интеграции механизмов поиска с языковыми моделями. Вы научитесь извлекать данные из специализированных источников, использовать их для поддержки генеративного процесса и оценивать качество полученных результатов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0uGRTx_xGI1"
      },
      "source": [
        "# Устанавливаем зависимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgVt4aB7Enn",
        "outputId": "1cfd2a3f-9832-4273-e15c-4fd17fa2d9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ij5l5xt6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ij5l5xt6\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 28d3148b079fa50b82f4888dfcc3cd3de953f956\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (2025.4.26)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.53.0.dev0-py3-none-any.whl size=11380784 sha256=0b1ccc92135a17c484da9a5fb5ce8fe62f34984e622df57521c80d4efe1a3dbc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ayog28tz/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "Successfully installed transformers-4.53.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyImHSqi7yrI",
        "outputId": "49aac5bb-cdae-4624-b13c-3590a6b83498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting sentence_transformers==3.3.1\n",
            "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (4.53.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==3.3.1) (11.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.6.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers==3.3.1) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers==3.3.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers==3.3.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers==3.3.1) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers==3.3.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers==3.3.1) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers==3.3.1) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers==3.3.1) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers==3.3.1) (3.0.2)\n",
            "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.17.0-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m811.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, datasets, sentence_transformers, trl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "  Attempting uninstall: sentence_transformers\n",
            "    Found existing installation: sentence-transformers 4.1.0\n",
            "    Uninstalling sentence-transformers-4.1.0:\n",
            "      Successfully uninstalled sentence-transformers-4.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence_transformers-3.3.1 trl-0.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets sentence_transformers==3.3.1 trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GSuCJ7owjgG"
      },
      "source": [
        "# Текст на чанки - 5 баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsuU9wgFw-tr"
      },
      "source": [
        "Для наших заданий будем использовать датасет rag-dataset-12000, в котором есть вопросы, ответы и большие контексты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665,
          "referenced_widgets": [
            "9f8649da557b4a8bb0dd27dbbc661b1d",
            "9eb047c2f5df48d785e0b90a5190be83",
            "7170178283c84fd6a4b73f182812f60d",
            "257de37041aa4c2da79badd524657ed5",
            "474c4cea665e4a25bcb635811a2bca8a",
            "aeae68558e5547f8b346f86e7f1ab4ca",
            "c1e8b4ebee174789bd1b51a7dcd115ce",
            "d71c5a1d1f2a4713ae1c1a70e9834b13",
            "7a0242ff6ced4c309473a63b6e21c6e0",
            "33dbbc08f1b545d3be4320e6b6befaf9",
            "8db8d4d9589f420fa7bb9145fda6d809",
            "6fdcfc9291eb48cfaa96ce2b1d8bedf3",
            "1065eda1ddbd4736a728cb2ff0bdbe28",
            "d2b8f847bd9e4a5e85a0c6d9aa685497",
            "10f350c0f5ce4a22bf2c5898558716a2",
            "256c5ab950954ab9a8990b16724a8403",
            "bae9541c487d4b819c17823587674bef",
            "b61b24169cb143308107ad98619a4ffc",
            "fb19a9bfce744e07a9ccd4a7f70f496d",
            "4695dbf26e4b4f2a8eeb8b5a2c4c2ec2",
            "08cd6c6c2e0d4940aec3f62d01899c4b",
            "46a3213c62224a3cb6af3d29b93c8134",
            "cf8be96c027c4d4fa28037674c9a25f2",
            "71b5493b18de4e09bfcf655f02fe744b",
            "8293eee8db9243909a174983115f279f",
            "aba487ae887144528c433f061019367f",
            "b8aefea6f0464bd3b72675d8501f154a",
            "8ef739359c834acfb2fba772cad1396f",
            "81670858d3d1406592549dd0893368af",
            "e2bf0708ae12458b811273fc6438d4a9",
            "dbaf4d91e96e4eda8b0ef6647f6ecbdb",
            "0134ffbefba3408ab143424827b31c1d",
            "cde0468fffd84b68930b4bef6c7a3200",
            "2153ee6742204d0f94f115b3a7e834bc",
            "21aff896fb774e468fd99868cf656eb0",
            "df33e2f8b5894f1ba5858a42723acc2e",
            "c41ebfb604474e119f0dda89c644c035",
            "f8153f7ecb6f495d9cca19c872401c2f",
            "4a1cdb8e2f9849fabc56267b11fdb422",
            "21f8f73abfe945769f4beb6f4e2bf101",
            "b911019a7dbe452aa8391a5f1513c653",
            "cba2a87fe2054b5d8a095e58d5737850",
            "af3f9c5d70a641fd8e327152bea8cb33",
            "5c336f9ca386464ca91bd8515c544cc7",
            "5776201f183142d1918f8eda83590a4e",
            "0c27f27361ea4c2b8eb14b457dbe7f4f",
            "4b5b32078de5439eb4fe3330e7d8de80",
            "f76601ecab8440b7997f5f172b6b02ef",
            "29f2a559e2c34741bbb609fd03a75687",
            "c06a92784280445c81266134974515a3",
            "bba75854aeed4a96aba5ab1dc9b827d5",
            "14ec7fa326384f3aa3ba49a4fa9fe267",
            "55623ae7462a46d28d1fc7be808cbd36",
            "b42b3cd494e44ba681d106ab34fba3ac",
            "e4170956b0f84aa789f989690efee2c0"
          ]
        },
        "id": "wGEzuBQk7TgS",
        "outputId": "fddb6e39-bb64-49f3-980f-61d3b104b1ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f8649da557b4a8bb0dd27dbbc661b1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-9df3a936e1f63191.parquet:   0%|          | 0.00/23.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fdcfc9291eb48cfaa96ce2b1d8bedf3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-af2a9f454ad1b8a3.parquet:   0%|          | 0.00/5.79M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf8be96c027c4d4fa28037674c9a25f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/9600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2153ee6742204d0f94f115b3a7e834bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5776201f183142d1918f8eda83590a4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9600\n",
            "What is the Berry Export Summary 2028 and what is its purpose? \n",
            "\n",
            "The Berry Export Summary 2028 is a dedicated export plan for the Australian strawberry, raspberry, and blackberry industries. It maps the sectors’ current position, where they want to be, high-opportunity markets, and next steps. The purpose of this plan is to grow their global presence over the next 10 years. \n",
            "\n",
            "Caption: Tasmanian berry grower Nic Hansen showing Macau chef Antimo Merone around his property as part of export engagement activities.\n",
            "THE RISE and rise of the Australian strawberry, raspberry and blackberry industries has seen the sectors redouble their international trade focus, with the release of a dedicated export plan to grow their global presence over the next 10 years.\n",
            "Driven by significant grower input, the Berry Export Summary 2028 maps the sectors’ current position, where they want to be, high-opportunity markets and next steps.\n",
            "Hort Innovation trade manager Jenny Van de Meeberg said the value and volume of raspberry and blackberry exports rose by 100 per cent between 2016 and 2017. She said the Australian strawberry industry experienced similar success with an almost 30 per cent rise in export volume and a 26 per cent rise in value to $32.6M over the same period.\n",
            "“Australian berry sectors are in a firm position at the moment,” she said. “Production, adoption of protected substrate cropping, improved genetics and an expanding geographic footprint have all helped put Aussie berries on a positive trajectory.\n",
            "“We are seeing a real transition point. Broad industry interest and a strong commercial appetite for export market development combined with the potential to capitalise on existing trade agreements and build new trade partnerships has created this perfect environment for growth.”\n",
            "High-income countries across Europe, North America and Northern Asia have been identified as having a palate for Australian grown berries with more than 4244 tonnes of fresh berries exported in the last financial year alone.\n",
            "The strategy identified the best short-term prospect markets for the Australian blackberry and raspberry industry as Hong Kong, Singapore, The United Arab Emirates and Canada. The strongest short-term trade options identified for the strawberry sector were Thailand, Malaysia, New Zealand and Macau.\n",
            "The strategy focuses heavily on growing the existing strawberry export market from 4 per cent to at least 8 per cent of national production by volume, in markets with a capacity and willingness to pay a premium for quality fruit. For raspberries and blackberries, the sectors aim to achieve a 5 per cent boost in exports assessed by volume across identified markets by 2021.\n",
            "Tasmanian raspberry exporter Nic Hansen said Australia offers some of the sweetest and most attractive berries in the world, and this combined with our stringent food safety standards across all stages of the supply chain puts growers in a solid position.\n",
            "“We have a great product, we are hungry to expand trade and now with this new plan in place, we have a clear roadmap towards driving growth,” Mr Hansen said.\n",
            "He said it is exciting to see new export market prospects for raspberries: “The more options we have for export the better. Now we just have to get on with the job of ensuring industry has all the tools it needs, such as supporting data and relationship building opportunities, to thrive in new markets.”\n",
            "This project was commissioned by Hort Innovation, and developed by market analysts and research consultants Auspex Strategic Advisory and AgInfinity. Hort Innovation will work now with berry sectors to determine levy-funded activities to support trade.\n",
            "See a summary of the strategy on the Hort Innovation website.\n",
            "For more information on the berry industries, refer to the Horticulture Statistics Handbook and the Strategic Investment Plans for strawberries, raspberries and blackberries. Growers seeking more information should email trade@horticulture.com.au \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "wikiq = load_dataset('neural-bridge/rag-dataset-12000')\n",
        "\n",
        "print(len(wikiq['train']))\n",
        "print(wikiq['train'][0]['question'], '\\n')\n",
        "print(wikiq['train'][0]['answer'], '\\n')\n",
        "print(wikiq['train'][0]['context'], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8pN_pIXxxfh"
      },
      "source": [
        "Для налаживания процессов возьме 100 самых длинных текстов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KrLSMxEjAmgE"
      },
      "outputs": [],
      "source": [
        "k_longest = 100\n",
        "train_data = sorted(wikiq['train'], key=lambda w: len(w[\"context\"]))[-k_longest:]\n",
        "\n",
        "train_full_docs = [elem['context'] for elem in train_data]\n",
        "train_queries = [elem['question'] for elem in train_data]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3fYgb-Wkt9yt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_text = train_full_docs[0].split(' ')\n",
        "chunk_words, overlap = 100, 30\n",
        "\n",
        "for start in tqdm(range(0, len(split_text), chunk_words-overlap)):\n",
        "  print(start, start+chunk_words)\n",
        "  chunk_i = split_text[start:start+chunk_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnd_vM7Nq7QZ",
        "outputId": "a462dd84-6b6f-44fe-e15f-c61a957e58b3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:00<00:00, 72593.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 100\n",
            "70 170\n",
            "140 240\n",
            "210 310\n",
            "280 380\n",
            "350 450\n",
            "420 520\n",
            "490 590\n",
            "560 660\n",
            "630 730\n",
            "700 800\n",
            "770 870\n",
            "840 940\n",
            "910 1010\n",
            "980 1080\n",
            "1050 1150\n",
            "1120 1220\n",
            "1190 1290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "807ZLp8Lx3Pr"
      },
      "source": [
        "Реализуйте класс Chunker, в котором метод split_text_to_chunks разбивает входный текст на чанки с перекрытием и возвращает список полученных чанков, и метод get_chunked_list, которые по списку текстов возвращает список чанков из этих текстов согласно методу split_text_to_chunks. Размер чанка и перекрытие измеряется в кол-ве слов, то есть chunk_words = 10 означает, что чанк состоит из 10 слов (слова - сущности, которые получаются после простого сплита строки по одному пробелу \" \"), перекрытие 3 означает, что если взять два соседний чанка, то 3 последних слова первого являются 3мя первыми словами второго чанка."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "_0AiV3BJ8yhB"
      },
      "outputs": [],
      "source": [
        "class Chunker:\n",
        "    def __init__(self, chunk_words: int = 100, overlap: int = 30):\n",
        "        # your code here\n",
        "        self.chunk_words = chunk_words\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def split_text_to_chunks(self, text: str) -> list[str]:\n",
        "        split_text = text.split(' ')\n",
        "        lst_chunks = []\n",
        "        for start in tqdm(range(0, len(split_text), self.chunk_words-self.overlap)):\n",
        "          chunk_i = split_text[start:start+self.chunk_words]\n",
        "          lst_chunks.append(' '.join(chunk_i))\n",
        "\n",
        "        return lst_chunks\n",
        "\n",
        "        # your code here\n",
        "\n",
        "    def get_chunked_list(self, texts: list[str]) -> list[str]:\n",
        "        # your code here\n",
        "        lst_chunks_text = []\n",
        "        for text in texts:\n",
        "          lst_chunks = self.split_text_to_chunks(text)\n",
        "          lst_chunks_text.append(lst_chunks)\n",
        "\n",
        "        return lst_chunks_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_full_docs[0]"
      ],
      "metadata": {
        "id": "lxu_8-iYvmoD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty39etCG_LEb",
        "outputId": "61fb365f-4aa8-413a-b9c0-a9d190964aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:00<00:00, 49216.08it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 99126.83it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 118776.75it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 91929.95it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 102612.94it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 93727.46it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 82342.16it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 137917.15it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 98980.63it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 112034.83it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 100285.75it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 97408.70it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 92820.01it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 107202.66it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 120916.87it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 99032.18it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 111237.39it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 80386.89it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 89749.73it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 93902.33it/s]\n",
            "100%|██████████| 13/13 [00:00<00:00, 81139.81it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 107892.06it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 83886.08it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 106422.64it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 124337.08it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 109297.82it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 113000.27it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 96095.91it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 92820.01it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 88168.55it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 101989.16it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 120699.40it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 92361.62it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 112034.83it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 82336.22it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 92820.01it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 92691.80it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 123589.07it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 103039.26it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 106861.25it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 135300.13it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 102144.39it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 117440.51it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 105012.03it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 120989.54it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 103991.01it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 120989.54it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 100144.90it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 91678.78it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 98766.97it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 115439.56it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 103337.92it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 99724.71it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 102456.28it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 95325.09it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 104550.10it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 144631.17it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 93596.74it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 98523.92it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 110740.70it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 97809.56it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 113936.95it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 91929.95it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 108035.10it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 83984.89it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 92004.09it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 114520.25it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 111411.20it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 119458.03it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 97400.38it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 80273.76it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 69977.96it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 94566.54it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 93328.75it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 49140.71it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 112682.79it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 102300.10it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 15193.52it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 108693.85it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 102153.54it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 74017.13it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 94965.37it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 81396.31it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 127341.30it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 96747.85it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 103563.06it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 123103.26it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 69905.07it/s]\n",
            "100%|██████████| 19/19 [00:00<00:00, 106255.70it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 77672.30it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 132533.77it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 138184.43it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 112821.47it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 96355.63it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 85393.02it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 107699.67it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 101139.25it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 95566.42it/s]\n",
            "100%|██████████| 18/18 [00:00<00:00, 91846.07it/s]\n",
            "100%|██████████| 19/19 [00:00<00:00, 138114.00it/s]\n"
          ]
        }
      ],
      "source": [
        "chunker = Chunker(chunk_words=100, overlap=30)\n",
        "train_chunked_docs = chunker.get_chunked_list(train_full_docs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_full_docs[0])"
      ],
      "metadata": {
        "id": "AkMYcldswaAU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_chunked_docs, '\\n')\n",
        "print(train_chunked_docs[0], '\\n')\n",
        "print(train_chunked_docs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELI8TrOavY6J",
        "outputId": "05948d91-7bd9-4529-873c-810b791ebfc9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The path to caregiver can be long and slow as one watches a friend or loved one slowly show signs of decline. It can also be quick and unexpected, brought on by sudden illness or accident. Slow or quick, this is the most difficult and often turbulent time for everyone involved. The first hurdle is recognizing and/or admitting that your loved one needs help. At the same time it is most difficult for the patient to admit the need for help.\\nThere can be a tremendous amount of denial as we begin to see the signs. At first this is usually', 'most difficult for the patient to admit the need for help.\\nThere can be a tremendous amount of denial as we begin to see the signs. At first this is usually facilitated by the loved one\\'s struggle to hide changes in ability. Vanity, pride, and stubbornness are very strong motivators and during this period they may intensify. The patient can be very clever at hiding difficulties. Often the future caregiver is only too eager to believe that everything is fine.\\n\"The first step toward change is awareness. The second step is acceptance.\"\\nnathaniel branden\\nI went through this struggle for the first time with', 'only too eager to believe that everything is fine.\\n\"The first step toward change is awareness. The second step is acceptance.\"\\nnathaniel branden\\nI went through this struggle for the first time with my own mother. I was young. My mother was good at hiding what was happening to her until the decline was too great to hide. Some bills went unpaid while others were paid more than once. She stacked piles of mail with the intention of \"looking at it later\". She began neglecting her personal hygiene. These things were completely out of character for the proud, strong and proper woman she', 'mail with the intention of \"looking at it later\". She began neglecting her personal hygiene. These things were completely out of character for the proud, strong and proper woman she had always been.\\nIt took a couple of serious falls and injuries for me to realize that something had to be done. I assumed the household and financial responsibilities. With the help of my sister, we tended to my mother\\'s personal chores. None of this was easy. There were so many emotional issues involved. I was embarrassed. I was sad. I was nearly overwhelmed. I learned and grew. I found a', 'chores. None of this was easy. There were so many emotional issues involved. I was embarrassed. I was sad. I was nearly overwhelmed. I learned and grew. I found a home health aide to come in a few days a week and this made all the difference.\\nIt is around this topic that I have gotten the most questions from friends and acquaintances. One of the most common themes is that a loved one is failing but refusing help. For a short time while she was in this transition period one of my friends would call me, exasperated that her mother', 'a loved one is failing but refusing help. For a short time while she was in this transition period one of my friends would call me, exasperated that her mother was refusing help. The mother was living on her own and belligerently independent. Medicine wasn\\'t being taken appropriately. She fell out of bed. Meals were being missed. My friend was worried and frightened but struggling with crossing the threshold from daughter to caregiver. My advice was that we need to decide when to override a loved one\\'s desire for independence for the sake of safety.\\nI remember saying: \"you wouldn\\'t leave', 'daughter to caregiver. My advice was that we need to decide when to override a loved one\\'s desire for independence for the sake of safety.\\nI remember saying: \"you wouldn\\'t leave your kids at home without a babysitter just because they didn\\'t want one\".\\nThere is a fine line between independence and neglect. We all walk that line and learn as we go. Some of us make better decisions than others. That friend of mine made all the right decisions. She took charge. She faced reality. She hired help. I have see others who have fallen on the other side.\\nThere was another', \"friend of mine made all the right decisions. She took charge. She faced reality. She hired help. I have see others who have fallen on the other side.\\nThere was another elderly gentleman that I knew. He also lived on his own. He was also failing. He had grown children who lived locally to him but just didn't take on the responsibilities. This guy was so obviously neglecting himself. He had become filthy. He was losing weight. He was falling frequently. He was still driving his car well beyond the point of safety.\\nI took it upon myself to make sure his\", 'become filthy. He was losing weight. He was falling frequently. He was still driving his car well beyond the point of safety.\\nI took it upon myself to make sure his children were aware of the situation. I made sure he had meals a few times a week. There wasn\\'t much I could do beyond that. This situation went on for several years. The children were either in denial or overwhelmed. Ultimately there was an incident involving his car and they woke up to the reality.\\nIt took a long time but they finally made the right decisions for their father\\'s well-being.\\n\"It\\'s', 'Ultimately there was an incident involving his car and they woke up to the reality.\\nIt took a long time but they finally made the right decisions for their father\\'s well-being.\\n\"It\\'s not the load that breaks you down - it\\'s the way you carry it.\"\\nlou holtz\\nAs I read today\\'s blog a few things came to mind. I\\'ve worked as a home health aide for about 10 years now. One of things that I have tried to suggest when first \"trying\" to introduce an aide into the home is to bring them in gradually. As the blog suggested it is a difficult', 'that I have tried to suggest when first \"trying\" to introduce an aide into the home is to bring them in gradually. As the blog suggested it is a difficult time when the \"loved one\" who needs the help refuses or more importantly doesn\\'t want to admit that they are in need of the help. By gradually introducing someone into the home, you are slowly sneaking them in to the daily routine and giving the \"loved one\" the opportunity to become friendly with the person first. For instance, bring the aide into the home for a brief period of time', 'daily routine and giving the \"loved one\" the opportunity to become friendly with the person first. For instance, bring the aide into the home for a brief period of time to perhaps just to do one load of laundry. The next time, have the aide bring the \"loved one\" to a doctors appointment and hopefully it\\'s a bright sunny day and they can stop for an ice cream cone on the way home. They need to develop a trusting friendship and that sometimes doesn\\'t come when and aide is thrown into the mix and forced upon the \"loved one\" who', 'the way home. They need to develop a trusting friendship and that sometimes doesn\\'t come when and aide is thrown into the mix and forced upon the \"loved one\" who is feeling like they are losing control of their own surroundings. I assure you it will become a lasting friendship and not just a caregiver/loved one relationship. The second point I wanted to touch on was the financial part of it. It can become very expensive depending on how many necessary hours a day might be needed to allow the \"loved one\" to stay in their own home/environment. The raw', 'it. It can become very expensive depending on how many necessary hours a day might be needed to allow the \"loved one\" to stay in their own home/environment. The raw fact is sometimes family members just DON\\'T have the funds! It can become a sacrifice for all involved but in the long run, everyone will recognize how much healthier it is and the dignity that remains with the \"loved one\" will be something that will enhance their quality of live in an environment that they know as Home!\\nCheryl thank you so much for your input. Your suggestions are spot-on. I', 'will be something that will enhance their quality of live in an environment that they know as Home!\\nCheryl thank you so much for your input. Your suggestions are spot-on. I am all to familiar with the financial question you raised. There is so little support for at-home care. It has been very expensive for me through the years.\\nThis post hit very close to home. We are currently dealing with this issue with my mom. She has been back and forth between hospital and rehab (for PT) since Feb 13. Before this latest incident she agreed that she would be better', 'issue with my mom. She has been back and forth between hospital and rehab (for PT) since Feb 13. Before this latest incident she agreed that she would be better off in assisted living, but we fear that at this point she needs more. She wants to go home after rehab but cannot be left alone. The thought of finding help for her in her home is daunting; how does one begin to find someone? My siblings and I are struggling with all the emotional and logistic aspects. Thanks for the post; it is comforting to know that others have', \"one begin to find someone? My siblings and I are struggling with all the emotional and logistic aspects. Thanks for the post; it is comforting to know that others have dealt with a similar situation and made it work. I don't know if Mom will end up in a nursing facility or not, but we try to remember that keeping her safe is what is important. It is strange (and sad) to think that I've gone I'm acting as her parent now.\\nDear Anonymous: If I can be of any help or if you'd just like some advice please feel free\", \"sad) to think that I've gone I'm acting as her parent now.\\nDear Anonymous: If I can be of any help or if you'd just like some advice please feel free to contact me directly. You can email me from my profile page. I have a lot of resources and contacts.\"] \n",
            "\n",
            "['The COP26 climate conference in Glasgow is over. Despite some progress, deep concerns remain about the outcomes. The final pact at least mentions the importance of exiting coal and the door remains open to ratcheting up national targets in 2022. But we’re all still on a long, hard road through wild and unfamiliar landscapes scarred by fires, floods and storms.\\nAccelerating the transition to a just and resilient zero-carbon future remains humanity’s most urgent task. Scientific evidence about global warming trends already locked in is, however, crystal clear: humans and all other species are on a journey into an increasingly harsh', 'humanity’s most urgent task. Scientific evidence about global warming trends already locked in is, however, crystal clear: humans and all other species are on a journey into an increasingly harsh climate future.\\nThis realisation raises two tough questions, which led me to begin work on my new book, Hope and Courage in the Climate Crisis:\\n– what sources of hope and wisdom can strengthen our capacity to take courageous and effective climate action?\\n– how do we live meaningful lives in a world of rapidly intensifying climate and ecological risks?\\nThere are times when I imagine all the ideas and voices I have drawn', 'action?\\n– how do we live meaningful lives in a world of rapidly intensifying climate and ecological risks?\\nThere are times when I imagine all the ideas and voices I have drawn on – scientists and activists, teachers and writers, poets and artists – gathered in respectful and intense debate. The conversations spark and crackle with fierce, urgent energy.\\nAll agree the hope we need is realistic and defiant. It is not wishful thinking, denial, or delay disguised as naïve optimism.\\nAs my research has helped me understand, humans continue to draw on a rich diversity of ideas to sustain defiant and courageous hope', 'thinking, denial, or delay disguised as naïve optimism.\\nAs my research has helped me understand, humans continue to draw on a rich diversity of ideas to sustain defiant and courageous hope in dark times.\\nRead more: Five things you need to know about the Glasgow Climate Pact\\nScience-based emergency action\\nI turn first to my colleagues from science and technology. Surely, they argue, our first priority remains speaking truth to power about the speed and scale of action needed to restore a safe climate?\\nTargets and agreements set at global conferences like COP26 are useful. But only if national and sub-national governments, cities and communities,', 'and scale of action needed to restore a safe climate?\\nTargets and agreements set at global conferences like COP26 are useful. But only if national and sub-national governments, cities and communities, unions and business all actually deliver on those targets and rapidly intensify their work to cut emissions, including a swift end to using coal, oil and gas.\\nOK, but how do we achieve the necessary political momentum? My climate activist friends seem less convinced by the promise of scientific evidence and reason.\\nThe pandemic response has been a useful wake-up call about the possibilities as well as the limits of human ingenuity.', 'seem less convinced by the promise of scientific evidence and reason.\\nThe pandemic response has been a useful wake-up call about the possibilities as well as the limits of human ingenuity. But in the climate crisis, how do we deploy data and evidence at the speed required, while avoiding the delusional hubris that there are always technical solutions to every human problem?\\nHistorical examples my activist colleagues turn to for inspiration are stories of solidarity and fellowship, where ethically informed collective action has achieved transformational change which once looked completely impossible.\\nThese include the anti-slavery movement, the Suffragettes, the overthrow of Apartheid and', 'stories of solidarity and fellowship, where ethically informed collective action has achieved transformational change which once looked completely impossible.\\nThese include the anti-slavery movement, the Suffragettes, the overthrow of Apartheid and the fall of the Berlin Wall. More recently we can look to examples like Black Lives Matter, 350.org, Pacific Climate Warriors, Beyond Zero Emissions, Market Forces and School Strike 4 Climate.\\nJustice, care and beauty\\nI turn next to my friends and colleagues from Indigenous and First Nation communities, such as the Seed Indigenous Youth Climate Network.\\nFrom them, we might learn to deepen our understanding of the histories of the lands on', 'colleagues from Indigenous and First Nation communities, such as the Seed Indigenous Youth Climate Network.\\nFrom them, we might learn to deepen our understanding of the histories of the lands on which we gather – and the legacies of colonialism, resistance and dispossession which have led us to these times of risk and crisis.\\nClimate justice – the principle that the burdens of climate change impacts and solutions should be shared fairly – is therefore one of the first propositions we should bring to the table.\\nIn thinking about the concept of climate justice I also find it helpful to bear in mind', '– is therefore one of the first propositions we should bring to the table.\\nIn thinking about the concept of climate justice I also find it helpful to bear in mind the responses Indigenous school students gave, when Indigenous author and activist Tony Birch asked them to define climate justice:\\nif we fail to care for Country, it cannot care for us\\nThis response highlights the importance of remembering that the principle of climate justice should not be restricted to humans alone.\\nI am joined next by teachers and scholars from a wide array of spiritual and faith-based traditions. They suggest the first key', 'climate justice should not be restricted to humans alone.\\nI am joined next by teachers and scholars from a wide array of spiritual and faith-based traditions. They suggest the first key step in times of suffering and despair is thankfulness.\\nBuddhist poet and environmental activist Gary Snyder makes this point very well. He notes that while many severe climate impacts may already be locked in, every day he feels gratitude to this world that is.\\nSnyder quotes Kobayashi Issa, a poet who once wrote:\\nThis dewdrop world\\nIs but a dewdrop world\\nAnd yet …\\nOur shared responsibility\\nRemembering the fragile impermanence of our dewdrop world is a', 'world that is.\\nSnyder quotes Kobayashi Issa, a poet who once wrote:\\nThis dewdrop world\\nIs but a dewdrop world\\nAnd yet …\\nOur shared responsibility\\nRemembering the fragile impermanence of our dewdrop world is a constant reminder of our shared responsibility to defend the beauty of the world we’ve been given, and hand this gift on to all humans and other species who’ll come after us.\\nHonouring and celebrating the astonishing, complex beauty of life on Earth is also, as legendary nature writer Rachael Carson reminds us, an abiding source of strength and inspiration:.\\nI turn finally to the theorists and writers, farmers and engineers, poets and', 'Earth is also, as legendary nature writer Rachael Carson reminds us, an abiding source of strength and inspiration:.\\nI turn finally to the theorists and writers, farmers and engineers, poets and artists and film makers who can help us imagine and create the regenerative action we need to cross the wild landscapes of the long climate emergency.\\nVisionary, insightful writers like Vandana Shiva, Jeremy Lent and George Monbiot who can help us clearly see the patterns and textures of our interwoven world, and understand and confront the ignorance, violence and greed threatening to tear this delicate fabric apart.\\nAuthors and activists such as', 'clearly see the patterns and textures of our interwoven world, and understand and confront the ignorance, violence and greed threatening to tear this delicate fabric apart.\\nAuthors and activists such as Rebecca Solnit, Kim Stanley Robinson, and Christiana Figueres, who can assist us navigate dangerous and uncertain times, remembering that the world is always full of surprises and the future is never fully settled.\\nSunlight on the water, wind in the trees\\nSo, where might we find sources of wisdom, hope and courage in this world of rapidly intensifying climate consequences?\\nHonesty with ourselves and others about the scale and consequences of the crisis', 'where might we find sources of wisdom, hope and courage in this world of rapidly intensifying climate consequences?\\nHonesty with ourselves and others about the scale and consequences of the crisis we now face. Scientific rigour, evidence and ingenuity. Working together, shoulder to shoulder to ignite and accelerate emergency speed action. Justice and care, respect and reciprocity. Thankfulness, kindness and compassion. Beauty, creativity and imagination.\\nAnd also these abiding gifts: the laughter of children. The comfort of old friends. Sunlight on the water, the wind in the trees, the silence of mountains, the roar of the ocean.\\nRead more: COP26: experts react to', \"of children. The comfort of old friends. Sunlight on the water, the wind in the trees, the silence of mountains, the roar of the ocean.\\nRead more: COP26: experts react to the UN climate summit and Glasgow Pact\\nJohn Wiseman is a Senior Research Fellow with Melbourne Climate Futures and Melbourne Sustainable Society Institute at the University of Melbourne; a Research Fellow with the Centre for Policy Development and a Board Member of The Next Economy.\\nHe is the author of 'Hope and Courage in the Climate Crisis', Palgrave Macmillan, 2021\", \"of The Next Economy.\\nHe is the author of 'Hope and Courage in the Climate Crisis', Palgrave Macmillan, 2021\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestChunker(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.chunker = Chunker(chunk_words=10, overlap=3)\n",
        "\n",
        "    def test_split_text_to_chunks_single_chunk(self):\n",
        "        \"\"\"Тест, когда текст меньше размера чанка.\"\"\"\n",
        "        text = \"word1 word2 word3\"\n",
        "        result = self.chunker.split_text_to_chunks(text)\n",
        "        self.assertEqual(result, [\"word1 word2 word3\"])\n",
        "\n",
        "    def test_split_text_to_chunks_no_overlap(self):\n",
        "        \"\"\"Тест, когда перекрытие равно 0.\"\"\"\n",
        "        chunker = Chunker(chunk_words=3, overlap=0)\n",
        "        text = \"word1 word2 word3 word4 word5 word6\"\n",
        "        result = chunker.split_text_to_chunks(text)\n",
        "        self.assertEqual(result, [\"word1 word2 word3\", \"word4 word5 word6\"])\n",
        "\n",
        "    def test_split_text_to_chunks_with_overlap(self):\n",
        "        \"\"\"Тест разбиения с перекрытием.\"\"\"\n",
        "        text = \"word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12\"\n",
        "        result = self.chunker.split_text_to_chunks(text)\n",
        "        expected = [\n",
        "            \"word1 word2 word3 word4 word5 word6 word7 word8 word9 word10\",\n",
        "            \"word8 word9 word10 word11 word12\"\n",
        "        ]\n",
        "        self.assertEqual(result, expected)\n",
        "\n",
        "    def test_split_text_to_chunks_edge_case(self):\n",
        "        \"\"\"Тест на граничный случай (ровное разбиение без остатка).\"\"\"\n",
        "        text = \"word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13\"\n",
        "        result = self.chunker.split_text_to_chunks(text)\n",
        "        expected = [\n",
        "            \"word1 word2 word3 word4 word5 word6 word7 word8 word9 word10\",\n",
        "            \"word8 word9 word10 word11 word12 word13\"\n",
        "        ]\n",
        "        self.assertEqual(result, expected)\n",
        "\n",
        "    def test_get_chunked_list_multiple_texts(self):\n",
        "        \"\"\"Тест обработки списка текстов.\"\"\"\n",
        "        chunker = Chunker(chunk_words=3, overlap=0)\n",
        "        texts = [\n",
        "            \"word1 word2 word3 word4 word5\",\n",
        "            \"word6 word7 word8 word9 word10 word11 word12 word13\"\n",
        "        ]\n",
        "        result = chunker.get_chunked_list(texts)\n",
        "        expected =[['word1 word2 word3', 'word4 word5'],\n",
        "                   ['word6 word7 word8', 'word9 word10 word11', 'word12 word13']]\n",
        "\n",
        "        self.assertEqual(result, expected)\n"
      ],
      "metadata": {
        "id": "Fi2m75iFvR2X"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFNcfT6oxFKl",
        "outputId": "be55ca6c-a564-4e84-e1be-c8fd2641ba15"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 13046.05it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 23831.27it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 27594.11it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 24966.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17772.47it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 36954.22it/s]\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.016s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_QlqbaGzQJ9"
      },
      "source": [
        "# Векторный поиск - 10 баллов\n",
        "\n",
        "Построить простой векторный поиск на основе энкодерной модели modernbert-embed-base. Модель устроена так, что эмбеддинги запросов (всегда должны начинаться с префикса \"search_query: \") всегда близки в векторном пространстве эмбеддингам похожих/релевантных документов (их текст всегда должен начинаться на \"search_document: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLpAgEhdCBgG"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "model = SentenceTransformer(\"nomic-ai/modernbert-embed-base\").to(device)\n",
        "\n",
        "query_embeddings = model.encode([\n",
        "    \"search_query: What is TSNE?\",\n",
        "    \"search_query: Who is Laurens van der Maaten?\",\n",
        "])\n",
        "doc_embeddings = model.encode([\n",
        "    \"search_document: TSNE is a dimensionality reduction algorithm created by Laurens van Der Maaten\",\n",
        "])\n",
        "print(query_embeddings.shape, doc_embeddings.shape)\n",
        "# (2, 768) (1, 768)\n",
        "\n",
        "similarities = model.similarity(query_embeddings, doc_embeddings)\n",
        "print(similarities)\n",
        "# tensor([[0.7214],\n",
        "#         [0.3260]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eetvsCSnCEJI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, embed_model_name: str = \"nomic-ai/modernbert-embed-base\",\n",
        "                 device: str = \"cuda\"):\n",
        "        self.embed_model = SentenceTransformer(embed_model_name).to(device)\n",
        "\n",
        "    def encode_query(self, texts: list[str]) -> np.ndarray:\n",
        "        # тут энкодим запросы, не забываем про префикс\n",
        "\n",
        "    def encode_docs(self, texts: list[str]) -> np.ndarray:\n",
        "        # тут энкодим документы, не забываем про префикс\n",
        "\n",
        "    def similarity(self, *args, **kwargs):\n",
        "        # тут считаем косинусную близость\n",
        "\n",
        "\n",
        "class VectorSearchEngine:\n",
        "    def __init__(self,\n",
        "                 init_base: list[str],\n",
        "                 encoder: Encoder,\n",
        "                 ):\n",
        "        # тут строим векторный индекс по исходной базе init_base с помощью энкодера\n",
        "\n",
        "    def insert_doc(self, doc: str) -> None:\n",
        "        # тут добавляем в векторный индекс и в список документов новый документ\n",
        "\n",
        "    def get_k_most_similar(self, query: str, k: int) -> tuple:\n",
        "        # тут пытаемся оптимально найти k ближайших для query документов, вернуть список текстов этих доков в порядке убывания близости,\n",
        "        # а также соответствующими им похожести"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wYwh0XnIvcU"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOhrRLA2Hvuz"
      },
      "outputs": [],
      "source": [
        "vse = VectorSearchEngine(train_chunked_docs[:3], encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbx4FwFuCEXk"
      },
      "outputs": [],
      "source": [
        "vse.get_k_most_similar(train_queries[0], k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKKPYiR3CD33"
      },
      "outputs": [],
      "source": [
        "train_queries[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4disQ6j17BS"
      },
      "source": [
        "# Генератор - 5 баллов\n",
        "\n",
        "Реализуйте метод generate генерации языковой модели, который по списку запросов выдает список текстовый ответов. **kwargs должны пойти как аргументы в model.generate при генерации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK5-2GVFLjCP"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8JBk3N8MSNn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, model_name: str = \"Qwen/Qwen2-0.5B\", device: str = \"cuda\" ):\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=\"auto\",\n",
        "            device_map=\"auto\"#=device\n",
        "        ).to(device)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def generate(self, inputs: list[str],\n",
        "                 **kwargs) -> str:\n",
        "        #  your code here\n",
        "\n",
        "def template_text(query: str, doc: str) -> str:\n",
        "    return f\"# Document: {doc}\\n\\n# Question: {query}\\n\\n# Answer: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9-mzD5mNi4M"
      },
      "outputs": [],
      "source": [
        "generator = Generator(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbwHNEmmNh5U"
      },
      "outputs": [],
      "source": [
        "doc = \"Turunturundia is a captivating and enigmatic country located in a secluded part of the world, yet to be discovered by adventurous travelers. The landscape of Turunturundia is a harmonious blend of expansive emerald plains, lush forests, and towering mountains capped with eternal snow. Its people are known for their warm hospitality and celebrate a rich tapestry of cultural traditions passed down through generations. Turunturundia's history is steeped in legends and folklore, with ancient ruins and artifacts indicating a civilization that valued art, philosophy, and nature. The capital of Turunturundia's is Turuncity. The country is also home to several unique species of flora and fauna found nowhere else on Earth, making it a treasure trove for botanists and ecologists alike. Despite its modest size, Turunturundia's spirit and charm leave a lasting impression on all who have the privilege of exploring its wonders.\"\n",
        "query = \"what is the capital of turunturundia?\"\n",
        "templated_example = template_text(query, doc)\n",
        "\n",
        "generator.generate([templated_example], max_new_tokens=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzzH87rd3LKu"
      },
      "source": [
        "# Генерация гипотез - 5 баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duoKuZsF2gLZ"
      },
      "source": [
        "функция template_text готовит вход в нужном формате. Реализуйте функцию create_hypotheses, которая по заданному входу генерирует n_candidates + 1 генераций:\n",
        "* n_candidates с помощью семплинга с заданной температурой\n",
        "* 1 кандидат - greedy генерация (без семлинга, макс вероятность каждого токена)\n",
        "и возвращает в формате: (гриди генерация, список семлпинг генераций)\n",
        "\n",
        "Семлпинг и его параметры можно найти в документации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zv_OA7QOgY6"
      },
      "outputs": [],
      "source": [
        "def create_hypotheses(templated_example: str,\n",
        "                      generator: Generator,\n",
        "                      temperature: float = 0.5,\n",
        "                      max_new_tokens: int = 512,\n",
        "                      n_candidates: int = 10) -> (str, list[str]):\n",
        "    # your code here\n",
        "\n",
        "doc = \"Turunturundia is a captivating and enigmatic country located in a secluded part of the world, yet to be discovered by adventurous travelers. The landscape of Turunturundia is a harmonious blend of expansive emerald plains, lush forests, and towering mountains capped with eternal snow. Its people are known for their warm hospitality and celebrate a rich tapestry of cultural traditions passed down through generations. Turunturundia's history is steeped in legends and folklore, with ancient ruins and artifacts indicating a civilization that valued art, philosophy, and nature. The capital of Turunturundia's is Turuncity. The country is also home to several unique species of flora and fauna found nowhere else on Earth, making it a treasure trove for botanists and ecologists alike. Despite its modest size, Turunturundia's spirit and charm leave a lasting impression on all who have the privilege of exploring its wonders.\"\n",
        "query = \"what is the capital of turunturundia?\"\n",
        "templated_example = template_text(query, doc)\n",
        "\n",
        "greedy_example, hypotheses = create_hypotheses(templated_example, generator)\n",
        "greedy_example, hypotheses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12WRV5xy35Bt"
      },
      "source": [
        "# Reward Model\n",
        "\n",
        "Возьмем из открытого доступа реворд-модель, которая обучалась понимать, какой из 2 ответов лучше, и будем использовать ее pointwise - для оценки одного ответа. Будем скорить всех сгенерированных на один запрос кандидатов и брать максимальный по скору. А пока просто посмотрим на ее ранжирующие свойства для кандидатов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SU1PS4j6NLt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "class RewardModel:\n",
        "    def __init__(self,\n",
        "                 model_name: str = \"OpenAssistant/reward-model-deberta-v3-large-v2\",\n",
        "                 device: str = \"cuda\"\n",
        "                 ):\n",
        "        rank_model, tokenizer = AutoModelForSequenceClassification.from_pretrained(model_name), AutoTokenizer.from_pretrained(model_name)\n",
        "        self.rank_model = rank_model.to(device)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def get_score(self, q: str, ans: str) -> float:\n",
        "        inputs = self.tokenizer(q, ans, return_tensors='pt').to(self.rank_model.device)\n",
        "        score = self.rank_model(**inputs).logits[0].cpu().detach()\n",
        "        return score\n",
        "\n",
        "\n",
        "reward_model = RewardModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eeldu-a7Lvg"
      },
      "outputs": [],
      "source": [
        "doc = \"Turunturundia is a captivating and enigmatic country located in a secluded part of the world, yet to be discovered by adventurous travelers. The landscape of Turunturundia is a harmonious blend of expansive emerald plains, lush forests, and towering mountains capped with eternal snow. Its people are known for their warm hospitality and celebrate a rich tapestry of cultural traditions passed down through generations. Turunturundia's history is steeped in legends and folklore, with ancient ruins and artifacts indicating a civilization that valued art, philosophy, and nature. The capital of Turunturundia's is Turuncity. The country is also home to several unique species of flora and fauna found nowhere else on Earth, making it a treasure trove for botanists and ecologists alike. Despite its modest size, Turunturundia's spirit and charm leave a lasting impression on all who have the privilege of exploring its wonders.\"\n",
        "query = \"what is the capital of turunturundia?\"\n",
        "templated_example = template_text(query, doc)\n",
        "\n",
        "greedy_example, hypotheses = create_hypotheses(templated_example, generator)\n",
        "\n",
        "ranks = []\n",
        "for ans in hypotheses:\n",
        "    score = reward_model.get_score(query, ans)\n",
        "    ranks.append((score, query, ans))\n",
        "\n",
        "sorted_ranks = sorted(ranks, key=lambda w: w[0])\n",
        "\n",
        "for elem in sorted_ranks:\n",
        "    print(elem, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r7ffYGT-p_n"
      },
      "source": [
        "# Всё вместе и RS - 10 баллов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR_XPQ9h8J2j"
      },
      "outputs": [],
      "source": [
        "k_longest = 100\n",
        "train_data = sorted(wikiq['train'], key=lambda w: len(w[\"context\"]))[-k_longest:]\n",
        "\n",
        "train_full_docs = [elem['context'] for elem in train_data]\n",
        "train_queries = [elem['question'] for elem in train_data]\n",
        "\n",
        "chunker = Chunker(chunk_words=100, overlap=30)\n",
        "train_chunked_docs = chunker.get_chunked_list(train_full_docs)\n",
        "\n",
        "encoder = Encoder(device=\"cpu\")\n",
        "vse = VectorSearchEngine(train_chunked_docs, encoder)\n",
        "\n",
        "generator = Generator()\n",
        "reward_model = RewardModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfOefA9o_7Hq"
      },
      "source": [
        "На основе решений выше соберите pandas датафрейм, в котором каждая строка будет состоять из запроса, контекста, одной из генераций (гриди или семплинг), типа генерации (гриди или семплинг) и значения реворда для данного ответа на данный запрос.\n",
        "Такие результаты должны быть получены для всех запросов из train_queries.\n",
        "В семплинг генерациях возьмите 10 кандидатов с дефолтной температурой, макс длина контекста 512 токенов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baHKPDzv8WJj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dct = {\n",
        "    \"query\" : [],\n",
        "    \"ctx\": [],\n",
        "    \"generation\": [],\n",
        "    \"type\": [],\n",
        "    \"score\": []\n",
        "}\n",
        "\n",
        "# your code here\n",
        "\n",
        "df = pd.DataFrame(dct)\n",
        "df['idx'] = np.arange(df.shape[0])\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0S3nEIc-M8z"
      },
      "outputs": [],
      "source": [
        "print(df[df[\"type\"] == \"greedy\"][\"score\"].mean())\n",
        "# среднее значение ревордов генератор без дообучения. После дообучения оно аналогичная статистика должна стать больше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55mBbe-GIFv"
      },
      "source": [
        "Напишите логику для Rejection Sampling: сохраните в best_score_df только те строки из df, в которых для запроса и контекста выбрана гипотеза с максимальным скором реворда. Посчитайте среднее значение реворда в такой выборке и сравните со среднем значениям только по гриди генерациям."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVO-MiknAjzy"
      },
      "outputs": [],
      "source": [
        "rows = []\n",
        "# your code here\n",
        "\n",
        "best_score_df = pd.DataFrame(rows)\n",
        "\n",
        "print(best_score_df[\"score\"].mean())\n",
        "best_score_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "759ZUyMMAVot"
      },
      "source": [
        "# Обучение - 10 баллов\n",
        "\n",
        "Попробуем улучшить наш генератор с помощью данных, полученных на предыдущем шаге. Весь пайплайн выглядит так:\n",
        "1. Мы сгенерировали ряд гипотез\n",
        "2. Мы оценили ответы с помощью reward модели\n",
        "3. Мы берем лучшие ответы для того, чтобы обучить на них модель\n",
        "\n",
        "Таким образом мы получим новый датасет, на котором сможем обучиться.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VeVLvMmpSqR"
      },
      "outputs": [],
      "source": [
        "# создаем датасет в нужном формате\n",
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    return template_text(example[\"query\"], example[\"ctx\"]) + example[\"generation\"].strip()\n",
        "\n",
        "dataset_raw = [{\"text\": formatting_prompts_func(sample)} for _, sample in best_score_df.iterrows()]\n",
        "print(*dataset_raw[:3], sep=\"\\n--------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctam7DzqpSqS"
      },
      "source": [
        "Дальше написан код обучения, подробнее, что как работает мы разберем на следующей лекции! Сейчас вам нужно проставить следующие параметры:\n",
        "* learning rate 2e-4\n",
        "* число шагов обучения или число эпох\n",
        "* агрументы для сохранения чекпоинта (save_strategy, save_steps...)\n",
        "\n",
        "Все аргументы описаны в [документации](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbPcvkmD18n6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "\n",
        "model = generator.model.float()\n",
        "tokenizer = generator.tokenizer\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "dataset = Dataset.from_list(dataset_raw)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "args = SFTConfig(\n",
        "    per_device_train_batch_size = 2,\n",
        "    gradient_accumulation_steps = 4,\n",
        "    warmup_steps = 5,\n",
        "\n",
        "\n",
        "    # Заполните этот блок аргументов\n",
        "    # num_train_epochs = 1, # 1 эпоха = 1 полный проход по данным\n",
        "    # max_steps = 60, # сколько шагов обучения сделать\n",
        "    save_strategy=...,\n",
        "    save_interval=...,\n",
        "    learning_rate = # ваш код здесь,\n",
        "    ############\n",
        "\n",
        "    fp16 = True,\n",
        "    logging_steps = 1,\n",
        "    optim = \"adamw_hf\",\n",
        "    weight_decay = 0.01,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    seed = 3407,\n",
        "    output_dir = \"outputs\",\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 512,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    report_to=None,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    args = args\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fbQJ_aPpSqS"
      },
      "source": [
        "После того, как вы обучили свою модель, давайте проверим наш пайплайн еще раз, посчитаем среднюю награду наших генераций, она должна была увеличиться"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqcbwyt0pSqS"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlSWKD8o1NUe"
      },
      "source": [
        "# Расширение запроса - 5 баллов\n",
        "\n",
        "Зачастую пользователи предоставляют нам неподробный запрос и хочется его переписать или расширить для лучшего поиска по базе данных. Мы рассмотрим самый простой вариант расширения запроса - давайте добавим в запрос синонимов к каждому слову! Для этого нам поможет wordnet!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og0lBnGupSqS"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "synsets = wordnet.synsets('dog')\n",
        "for sn in synsets[:3]:\n",
        "    for lemma in sn.lemmas()[:4]:\n",
        "        print(lemma.name().replace(\"_\", \" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4P7noqDpSqT"
      },
      "source": [
        "Ваша задача дописать функцию expand_query: она должна проходиться по всем словам из текста и добавлять по одному синониму на каждое слово в запрос. Посмотрите, как поменяется близость между расширенным query и documents по сравнению с обычнм query и documents!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "resCZfOJpSqT"
      },
      "outputs": [],
      "source": [
        "def expand_query(query: str) -> str:\n",
        "    words = query.split()\n",
        "    # ваш код здесь\n",
        "    pass\n",
        "\n",
        "documents = [\n",
        "    \"The Eiffel Tower is a landmark in Paris, France.\",\n",
        "    \"Paris is the capital of France and known for its art, fashion, and culture.\",\n",
        "    \"France has a rich history, including revolutions and world wars.\",\n",
        "    \"The Louvre Museum in Paris holds many famous artworks, including the Mona Lisa.\"\n",
        "]\n",
        "query = \"Paris landmarks\"\n",
        "model = encoder.embed_model\n",
        "# ваш код здесь"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
        },
        "9eb047c2f5df48d785e0b90a5190be83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeae68558e5547f8b346f86e7f1ab4ca",
            "placeholder": "​",
            "style": "IPY_MODEL_c1e8b4ebee174789bd1b51a7dcd115ce",
            "value": "README.md: 100%"
          }
        },
        "7170178283c84fd6a4b73f182812f60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71c5a1d1f2a4713ae1c1a70e9834b13",
            "max": 5177,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a0242ff6ced4c309473a63b6e21c6e0",
            "value": 5177
          }
        },
        "257de37041aa4c2da79badd524657ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33dbbc08f1b545d3be4320e6b6befaf9",
            "placeholder": "​",
            "style": "IPY_MODEL_8db8d4d9589f420fa7bb9145fda6d809",
            "value": " 5.18k/5.18k [00:00&lt;00:00, 302kB/s]"
          }
        },
        "474c4cea665e4a25bcb635811a2bca8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeae68558e5547f8b346f86e7f1ab4ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e8b4ebee174789bd1b51a7dcd115ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d71c5a1d1f2a4713ae1c1a70e9834b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a0242ff6ced4c309473a63b6e21c6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33dbbc08f1b545d3be4320e6b6befaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db8d4d9589f420fa7bb9145fda6d809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fdcfc9291eb48cfaa96ce2b1d8bedf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1065eda1ddbd4736a728cb2ff0bdbe28",
              "IPY_MODEL_d2b8f847bd9e4a5e85a0c6d9aa685497",
              "IPY_MODEL_10f350c0f5ce4a22bf2c5898558716a2"
            ],
            "layout": "IPY_MODEL_256c5ab950954ab9a8990b16724a8403"
          }
        },
        "1065eda1ddbd4736a728cb2ff0bdbe28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae9541c487d4b819c17823587674bef",
            "placeholder": "​",
            "style": "IPY_MODEL_b61b24169cb143308107ad98619a4ffc",
            "value": "(…)-00000-of-00001-9df3a936e1f63191.parquet: 100%"
          }
        },
        "d2b8f847bd9e4a5e85a0c6d9aa685497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb19a9bfce744e07a9ccd4a7f70f496d",
            "max": 23101821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4695dbf26e4b4f2a8eeb8b5a2c4c2ec2",
            "value": 23101821
          }
        },
        "10f350c0f5ce4a22bf2c5898558716a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08cd6c6c2e0d4940aec3f62d01899c4b",
            "placeholder": "​",
            "style": "IPY_MODEL_46a3213c62224a3cb6af3d29b93c8134",
            "value": " 23.1M/23.1M [00:00&lt;00:00, 39.2MB/s]"
          }
        },
        "256c5ab950954ab9a8990b16724a8403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae9541c487d4b819c17823587674bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b61b24169cb143308107ad98619a4ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb19a9bfce744e07a9ccd4a7f70f496d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4695dbf26e4b4f2a8eeb8b5a2c4c2ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08cd6c6c2e0d4940aec3f62d01899c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a3213c62224a3cb6af3d29b93c8134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8be96c027c4d4fa28037674c9a25f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71b5493b18de4e09bfcf655f02fe744b",
              "IPY_MODEL_8293eee8db9243909a174983115f279f",
              "IPY_MODEL_aba487ae887144528c433f061019367f"
            ],
            "layout": "IPY_MODEL_b8aefea6f0464bd3b72675d8501f154a"
          }
        },
        "71b5493b18de4e09bfcf655f02fe744b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef739359c834acfb2fba772cad1396f",
            "placeholder": "​",
            "style": "IPY_MODEL_81670858d3d1406592549dd0893368af",
            "value": "(…)-00000-of-00001-af2a9f454ad1b8a3.parquet: 100%"
          }
        },
        "8293eee8db9243909a174983115f279f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2bf0708ae12458b811273fc6438d4a9",
            "max": 5789757,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbaf4d91e96e4eda8b0ef6647f6ecbdb",
            "value": 5789757
          }
        },
        "aba487ae887144528c433f061019367f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0134ffbefba3408ab143424827b31c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_cde0468fffd84b68930b4bef6c7a3200",
            "value": " 5.79M/5.79M [00:00&lt;00:00, 104MB/s]"
          }
        },
        "b8aefea6f0464bd3b72675d8501f154a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef739359c834acfb2fba772cad1396f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81670858d3d1406592549dd0893368af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2bf0708ae12458b811273fc6438d4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbaf4d91e96e4eda8b0ef6647f6ecbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0134ffbefba3408ab143424827b31c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde0468fffd84b68930b4bef6c7a3200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2153ee6742204d0f94f115b3a7e834bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21aff896fb774e468fd99868cf656eb0",
              "IPY_MODEL_df33e2f8b5894f1ba5858a42723acc2e",
              "IPY_MODEL_c41ebfb604474e119f0dda89c644c035"
            ],
            "layout": "IPY_MODEL_f8153f7ecb6f495d9cca19c872401c2f"
          }
        },
        "21aff896fb774e468fd99868cf656eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1cdb8e2f9849fabc56267b11fdb422",
            "placeholder": "​",
            "style": "IPY_MODEL_21f8f73abfe945769f4beb6f4e2bf101",
            "value": "Generating train split: 100%"
          }
        },
        "df33e2f8b5894f1ba5858a42723acc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b911019a7dbe452aa8391a5f1513c653",
            "max": 9600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cba2a87fe2054b5d8a095e58d5737850",
            "value": 9600
          }
        },
        "c41ebfb604474e119f0dda89c644c035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3f9c5d70a641fd8e327152bea8cb33",
            "placeholder": "​",
            "style": "IPY_MODEL_5c336f9ca386464ca91bd8515c544cc7",
            "value": " 9600/9600 [00:00&lt;00:00, 23572.06 examples/s]"
          }
        },
        "f8153f7ecb6f495d9cca19c872401c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1cdb8e2f9849fabc56267b11fdb422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f8f73abfe945769f4beb6f4e2bf101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b911019a7dbe452aa8391a5f1513c653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cba2a87fe2054b5d8a095e58d5737850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af3f9c5d70a641fd8e327152bea8cb33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c336f9ca386464ca91bd8515c544cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5776201f183142d1918f8eda83590a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c27f27361ea4c2b8eb14b457dbe7f4f",
              "IPY_MODEL_4b5b32078de5439eb4fe3330e7d8de80",
              "IPY_MODEL_f76601ecab8440b7997f5f172b6b02ef"
            ],
            "layout": "IPY_MODEL_29f2a559e2c34741bbb609fd03a75687"
          }
        },
        "0c27f27361ea4c2b8eb14b457dbe7f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06a92784280445c81266134974515a3",
            "placeholder": "​",
            "style": "IPY_MODEL_bba75854aeed4a96aba5ab1dc9b827d5",
            "value": "Generating test split: 100%"
          }
        },
        "4b5b32078de5439eb4fe3330e7d8de80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ec7fa326384f3aa3ba49a4fa9fe267",
            "max": 2400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55623ae7462a46d28d1fc7be808cbd36",
            "value": 2400
          }
        },
        "f76601ecab8440b7997f5f172b6b02ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42b3cd494e44ba681d106ab34fba3ac",
            "placeholder": "​",
            "style": "IPY_MODEL_e4170956b0f84aa789f989690efee2c0",
            "value": " 2400/2400 [00:00&lt;00:00, 8230.50 examples/s]"
          }
        },
        "29f2a559e2c34741bbb609fd03a75687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06a92784280445c81266134974515a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba75854aeed4a96aba5ab1dc9b827d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ec7fa326384f3aa3ba49a4fa9fe267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55623ae7462a46d28d1fc7be808cbd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b42b3cd494e44ba681d106ab34fba3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4170956b0f84aa789f989690efee2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
