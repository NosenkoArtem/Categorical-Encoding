{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NosenkoArtem/Categorical-Encoding/blob/master/hw4_NosenkoArtem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXUMzcKXAe-t"
      },
      "source": [
        "# Домашние задание: введение в LLM 2\n",
        "\n",
        "В этом домашнем задании мы разберем более современные архитектурные модификации LLM такие как RoPE, RMSNorm и обучим свою мини-LLM с нуля"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFd4gLTldVdQ",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gmf-HyiWAe-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20698ec2-c3de-4c47-e802-701f23f51720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-27 20:26:40--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-03-27 20:26:40 (30.3 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WbhRahnmAe-u",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0772f913-479b-41be-ca52-0869102ae1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jaxtyping==0.2.34\n",
            "  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting transformers==4.48.2\n",
            "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard==2.13.3 (from jaxtyping==0.2.34)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (2025.1.31)\n",
            "Downloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, jaxtyping, transformers\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.50.0\n",
            "    Uninstalling transformers-4.50.0:\n",
            "      Successfully uninstalled transformers-4.50.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jaxtyping-0.2.34 transformers-4.48.2 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "! pip install jaxtyping==0.2.34 transformers==4.48.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "V0_q9RgkAe-u"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# import torch\n",
        "\n",
        "import torch as t\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple, List, Optional, Dict, Callable\n",
        "from jaxtyping import Float, Int\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r0F_eNOwAe-v"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShmayLkUAe-v"
      },
      "source": [
        "# Подготовка данных - 15 баллов\n",
        "\n",
        "У нас есть текст пьесы Шекспира"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Iy1HnnYUAe-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1a6b9f-e3ba-47df-8bdf-83c75e7dcf56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ]
        }
      ],
      "source": [
        "with open(\"input.txt\") as fin:\n",
        "    text = fin.read()\n",
        "\n",
        "print(text[:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-MY46CLAe-v"
      },
      "source": [
        "Создаем токенайзер, обратите внимание, что у токена there должен быть вначале спецсимвол, обозначающий, что это новое слово, а не часть предыдущего!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5oYGENv4Ae-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "4551b35eb7a846909a713e2c8ca94d5a",
            "c8fa3fb64d2d40fea0bde0d04700f94d",
            "70002f9acc544a27a453f7324d2e6e6d",
            "007f4be422f842eea3e64b6ab483e34d",
            "9e533448953f4f6a9ae7df8059b5ac38",
            "ef40650ffc6248beaa6bc925d9e75023",
            "c04cf57ba2b1444d9e10779a8376bb5f",
            "196848efa3e946878d340b078e8cf42d",
            "f20eec2ba4c04b68b03ce95f1150a36a",
            "a81c91b855484378ae7acaeb695a89c2",
            "d340aa9c6c4e441aae2936eef7ee2076",
            "3fa1059503274060a8470478c0592d21",
            "a50b562a2b734d2a98708fa2551d27c0",
            "65a32cc969104cd99c3968e240cb404a",
            "b02ae3df46d24d288583dff04477ec6a",
            "6622c34237464a84a6eaefaf2a10a360",
            "f2dfb19c2cf345f28dc24cb479b6f622",
            "7963308e0c84484ba1211fd2a7d65a4f",
            "07889b1d54074bfea36408785f62b6c6",
            "ac4ef159619b4349ba5e9c8cfa7937a4",
            "2f4abae0b6704ca581267290aec95962",
            "5cd6fb0bf06042b692541f70dda450b0",
            "7bd8ad11268246aaab7f7571a0b34255",
            "36286884ccf648beb98012e2828bd488",
            "cbc49c64ce7646e483241d75dadba1a3",
            "e305875fdcfa4544a157c626d0702ca5",
            "2f024b9a303849dba451e68fe65cfb49",
            "350d1a6e303441c1948ccd13951e016c",
            "d0ddd4c6460b476593c4a19055a17575",
            "497cbcd021ad4f4480ec66aa94cadf1f",
            "81113f01de294615a90e3a30422940ad",
            "01d51cb362704ed8a2d10e5174d88148",
            "f111d8ebccfb45fea39f643f2c5b0784",
            "2f1211d5b170469fbe0f13be94729541",
            "b5d8a6be97b443f1b0fc9c1516b80c2e",
            "ae99f81d45b3494ea4bee7f94767246e",
            "7a0dc3b6780243239cb35af68b4b1517",
            "32817f032ed049feace817adb4d8dc5b",
            "b6b1fc4b066948329ef600f1988fe4f6",
            "409cff701a0b41ce8832a4e07591a3e0",
            "83ae005f24ca4162a69289eb9c8c0325",
            "c5c1e02972d74e2e9e9304841ec3830d",
            "cee0a60fd5084151b78e1c7c4669ed29",
            "20eff29063bb4362aa3312cf71886d37",
            "63151483bdaf45b1af907be532312df4",
            "ed9b8175f42e4a50b8490ec92c36bda7",
            "a56e76795b5347ddba8971d899a89340",
            "bb9e9f52f59c4b929c2a4ebdb7839205",
            "928ff9cb73c946478e3d11748672230f",
            "2c87741f297942d5b78d39c5e6e7328e",
            "bf9e82197e914ab3a78a1e380fc95ccc",
            "88a9c9c533e4419e8c30540785721049",
            "4ee015106ca24a1aa8b7ab12b92dc67e",
            "c2185978ef8b48759eca387b5f50c84c",
            "bb9e6dfea6d2489597eafe386b89e1ba"
          ]
        },
        "outputId": "5a78f4c4-25f7-4282-c51e-528a6ca83324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4551b35eb7a846909a713e2c8ca94d5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fa1059503274060a8470478c0592d21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bd8ad11268246aaab7f7571a0b34255"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f1211d5b170469fbe0f13be94729541"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63151483bdaf45b1af907be532312df4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Ġthere', 'Ġsomet', 'r', 'ash', 'token']\n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "print(tokenizer.tokenize(\"Hello there sometrashtoken\"))\n",
        "print(tokenizer.eos_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvG3nmMWAe-v"
      },
      "source": [
        "В токенайзере нет спецтокена под паддинг, поэтому выставим PAD_TOKEN = EOS_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MWFwF_AUAe-w"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G02RQgzx857U",
        "outputId": "0fcbc545-3a1f-43e6-924b-1d44c498f0c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEgfc1KaAe-w"
      },
      "source": [
        "## Датасет - 5 баллов\n",
        "\n",
        "Нам нужен Dataset - что-то, что будет держать данные.\n",
        "Почитать подробнее можно в [документации](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) или на [примерах](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n",
        "\n",
        "\n",
        "Если кратко:\n",
        "* Dataset должен реализовывать 2 метода: `__getitem__` для получения сэмплов и `__len__` для получения длины датасета\n",
        "* Нужна функция collate_fn - она будет собирать несколько сэмплов из датасета в один батч\n",
        "* Нужен DataLoader - объект, который будет брать объекты из датасета и с помощью collate_fn возвращать батчи\n",
        "* Нужен Sampler - объект, который помогает DataLoader выбирать батчи. В нашем случае это будет просто рандом, но можно собирать сэмплы по одинаковой длине или упорядочить в зависимости от задачи.\n",
        "\n",
        "\n",
        "Начнем с Dataset. В нем нужно дописать 3 функции, самая важная конструктор `__init__`:\n",
        "1. Принимает корпус текста\n",
        "2. Токенизирует его весь\n",
        "2. Бьем текст на непересекающиеся окна размером 200-300 токенов (длину определяем с помощью random.randint)\n",
        "3. Кладет токены в self.texts полученный List\\[int\\], то есть уже векторизованные тексты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1p8O1_VGAe-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d688a44-f64f-406c-a059-a3532f1c9440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (338025 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer: AutoTokenizer, text: str):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = []\n",
        "        random.seed(1)\n",
        "        tokens = tokenizer.encode(text)\n",
        "        chunk_size = random.randint(200, 300)\n",
        "        for i in range(0, len(tokens), chunk_size):\n",
        "            chunk = tokens[i:i+chunk_size]\n",
        "            self.texts.append(chunk)\n",
        "        # ---- Ваш код здесь ----\n",
        "        # raise NotImplemented()\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index) -> List[int]:\n",
        "        return self.texts[index]\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.texts)\n",
        "\n",
        "\n",
        "dataset = MyDataset(tokenizer, text)\n",
        "\n",
        "sample_0 = dataset.tokenizer.decode(dataset[0])\n",
        "\n",
        "assert sample_0.startswith(text[:100])\n",
        "\n",
        "print(sample_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWjLvpw5Ae-w"
      },
      "source": [
        "## Collate FN - 5 баллов\n",
        "Функция сборки, она же collate_fn. Она принимает батч сэмплов, т.е. список объектов, которые нам возвращает датасет!\n",
        "Она должна принимать `List[List[int]]` батч объектов и возвращать 2 тензора:\n",
        "\n",
        "* input_ids - `[batch, seq_len]` - батч токенов, в котором добавлены паддинги до максимальной длины в **текущем батче**.\n",
        "* mask - `[batch, seq_len]` - батч масок. На позиции `[i, j]` стоит 0, если токен является паддингом, иначе 1.\n",
        "\n",
        "В качестве значения паддинга для input_ids используйте `tokenizer.pad_token_id`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import tensor"
      ],
      "metadata": {
        "id": "1EjvPY9q7-Wb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AizeF272Ae-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88aaceab-f8d1-4b60-ace0-6b51af2075d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All good\n"
          ]
        }
      ],
      "source": [
        "def collate_fn(batch: List[List[int]]) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "  batch = [torch.tensor(x) for x in batch]\n",
        "  pad_batch_tensor = pad_sequence(batch, batch_first=True,\n",
        "                                  padding_value=tokenizer.pad_token_id).long()\n",
        "  mask = (pad_batch_tensor != tokenizer.pad_token_id).long()\n",
        "\n",
        "  return pad_batch_tensor, mask\n",
        "\n",
        "    # ---- Ваш код здесь ----\n",
        "    # raise NotImplemented()\n",
        "    # ---- Конец кода ----\n",
        "\n",
        "\n",
        "\n",
        "batch = [\n",
        "    [1, 2, 3, 4],\n",
        "    [1, 2],\n",
        "    [1, 2, 3, 4, 5, 6, 7],\n",
        "]\n",
        "input_ids_ref = torch.LongTensor([\n",
        "    [1, 2, 3, 4, 50256, 50256, 50256],\n",
        "    [1, 2, 50256, 50256, 50256, 50256, 50256],\n",
        "    [1, 2, 3, 4, 5, 6, 7],\n",
        "])\n",
        "\n",
        "\n",
        "mask_ref = torch.LongTensor([\n",
        "    [1, 1, 1, 1, 0, 0, 0],\n",
        "    [1, 1, 0, 0, 0, 0, 0],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "])\n",
        "\n",
        "input_ids, mask = collate_fn(batch)\n",
        "\n",
        "assert (input_ids == input_ids_ref).all()\n",
        "assert (mask == mask_ref).all()\n",
        "print(\"All good\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL3BTOpzAe-w"
      },
      "source": [
        "## Соберем DataLoader - 5 баллов\n",
        "\n",
        "Нужно заполнить пропущенные поля и убедиться, что в датасете есть замаскированные токены!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VSrQoUK8Ae-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7272e2fe-8984-4c8a-95e3-b128c844492b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all good\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.sampler import RandomSampler\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "sampler = RandomSampler(dataset)\n",
        "train_loader = DataLoader(dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          collate_fn=collate_fn,\n",
        "                          sampler=sampler,\n",
        "                          # shuffle=(sampler is None)\n",
        ")\n",
        "\n",
        "# ---- Конец кода ----\n",
        "\n",
        "\n",
        "for input_ids, mask in train_loader:\n",
        "    break\n",
        "\n",
        "assert (mask.sum(dim=1) < mask.size(1)).sum() < mask.size(0)\n",
        "assert input_ids.size(0) == 16\n",
        "print(\"all good\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Qz2wINAe-w"
      },
      "source": [
        "# Transformer - 20 баллов\n",
        "\n",
        "Немного модфицированный блок трансформера, который мы скопируем с предыдущего занятия!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QJZ2X636Ae-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5d0cc5-b0a4-4ff6-a275-a25d62a5ada1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768 # он же hidden_dim - внутрення размерность модели\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257 # он же vocab_size, размер словаря модели\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024 # число позиционных эмбеддингов\n",
        "    d_head: int = 64 # размерность головы аттеншена\n",
        "    d_mlp: int = 3072 # внутренняя размерность FFN-слоя\n",
        "    n_heads: int = 12 # число голов аттеншена\n",
        "    n_layers: int = 12 # число слоев трансформера\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv4YukVYAe-w"
      },
      "source": [
        "Эти модули остаются без изменений!\n",
        "Скопируйте их из предыдущего домашнего задания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "bGGzGdw4Ae-w"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import embedding\n",
        "\n",
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
        "        # Ваш код здесь!\n",
        "\n",
        "        # return self.W_E[input_ids]\n",
        "        # return einops.rearrange(self.W_E[input_ids], \"batch seq_len d_model -> batch seq_len d_model\")\n",
        "        return embedding(input_ids, self.W_E)\n",
        "\n",
        "\n",
        "\n",
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
        "    ) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
        "        # Ваш код здесь!\n",
        "        return x @ self.W_U + self.b_U\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
        "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
        "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
        "        # Ваш код здесь\n",
        "        x_lin = x @ self.W_in + self.b_in\n",
        "        z = F.gelu(x_lin, approximate=\"tanh\")\n",
        "        out = z @ self.W_out + self.b_out\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnbApshmAe-x"
      },
      "source": [
        "## RMSNorm - 5 баллов\n",
        "\n",
        "Здесь нужно написать RMSNorm. В качестве формулы стоит ориентироваться на формулу 4 из [статьи RMSNorm](https://arxiv.org/pdf/1910.07467)\n",
        "\n",
        "\n",
        "$$\\bar{x}_i = \\frac{x_i}{\\text{RMS}(\\mathbf{x})} w_i, \\quad \\text{where} \\quad \\text{RMS}(\\mathbf{x}) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} x_i^2}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "x7cAYjNEAe-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6df147d-df4c-4cff-8c5c-5c0343729f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model)) # gamma\n",
        "\n",
        "    def forward(self, x: Float[Tensor, \"batch seq_len d_model\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
        "        # ---- Ваш код здесь ----\n",
        "        # raise NotImplemented()\n",
        "        return x / ((x ** 2).mean(-1, keepdim=True)) ** 0.5\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "\n",
        "cfg_rmsnorm = Config(d_model=5)\n",
        "x = torch.Tensor([[[0.1, 0.2, 0.3, 0.4, 0.5]]]).to(device)\n",
        "layer = RMSNorm(cfg_rmsnorm).to(device)\n",
        "y = torch.Tensor([[[0.3015, 0.6030, 0.9045, 1.2060, 1.5076]]]).to(device)\n",
        "assert torch.allclose(y, layer(x), atol=1e-4, rtol=1e-3)\n",
        "print(\"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1n931-AAe-x"
      },
      "source": [
        "## Rotary Embeddings - 5 баллов\n",
        "\n",
        "Нужно написать роторные эмбеддинги из [статьи](https://arxiv.org/pdf/2104.09864). В качестве формулы нужно взять пункт 3.4.2!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "A0265gIuAe-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d7822a-cd33-49c6-c9d0-a69cbaa412ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тесты прошли успешно!\n"
          ]
        }
      ],
      "source": [
        "class RotaryPositionalEmbeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg: Config, theta: int = 10_000):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.max_seq_len = cfg.n_ctx\n",
        "        self.theta = theta\n",
        "        self.d = cfg.d_head\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        # Углы theta_i. Смотрите секуцию 2.2 статьи для формулы!\n",
        "        freqs = 1 / ((self.theta) ** (torch.arange(0, self.d, 2).float() / self.d))\n",
        "        position_id = torch.arange(0, self.max_seq_len).float()\n",
        "\n",
        "        # нужно получить матрицу m theta_i размера [max_seq_len, self.d] вида m theta_i\n",
        "        # где m берется из position_id, а theta из freqs\n",
        "\n",
        "        idx_theta = torch.outer(position_id, freqs)   #(max_seq_len, self.d)\n",
        "\n",
        "        # max_seq_len, d_head\n",
        "        cos = idx_theta.cos()\n",
        "        sin = idx_theta.sin()\n",
        "\n",
        "        # нужно продублировать размерности для формулы 34. theta_i встерчается два раза подряд в синусах и косинуса\n",
        "        # тут нам поможет torch.repeat_interleave\n",
        "        cos = cos.repeat_interleave(2, dim=1)          #(max_seq_len, 2*self.d)\n",
        "        sin =  sin.repeat_interleave(2, dim=1)         #(max_seq_len, 2*self.d)\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "\n",
        "        # 1, max_seq_len, 1, d_head\n",
        "        self.register_buffer(\"sin\", sin.view(1, self.max_seq_len, 1, self.d))\n",
        "        self.register_buffer(\"cos\", cos.view(1, self.max_seq_len, 1, self.d))\n",
        "\n",
        "    @staticmethod\n",
        "    def rotate_neg_vector(x: Float[torch.Tensor, \"batch seq_len num_heads d_head\"]):\n",
        "        # На входе x = [x1, x2, x3, x4, ... x_{n-1}, x_n]\n",
        "        # На выходе x' = [-x2, x1, -x4, x3, ..., -x_n, x_{n-1}]\n",
        "        x_new = torch.empty_like(x)\n",
        "\n",
        "        x_new[:, :, :, ::2] = - x[:, :, :, 1::2] # отрицательные значения\n",
        "        x_new[:, :, :, 1::2] = x[:, :, :, ::2]   # положительные значения\n",
        "        # ---- Ваш код здесь ----\n",
        "        # raise NotImplemented()\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "        return x_new\n",
        "\n",
        "    def forward(self, x: Float[torch.Tensor, \"batch seq_len num_heads d_head\"]):\n",
        "        seq_len = x.size(1)\n",
        "        x_rot = self.rotate_neg_vector(x)\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        x_rope = x * self.cos[:, :seq_len, :, :] + x_rot * self.sin[:, :seq_len, :, :] # формула 34\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "        return x_rope\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 1\n",
        "seq_len = 3\n",
        "num_heads = 1\n",
        "d_head = 16\n",
        "\n",
        "torch.manual_seed(1)\n",
        "x = torch.rand(batch_size, seq_len, num_heads, d_head)\n",
        "\n",
        "rope_config = Config(\n",
        "    n_heads=2,\n",
        "    d_head=16,\n",
        ")\n",
        "\n",
        "rope_layer = RotaryPositionalEmbeddings(rope_config)\n",
        "y = rope_layer(x)\n",
        "\n",
        "\n",
        "from math import sin, cos\n",
        "\n",
        "\n",
        "thetas = [10_000 ** (-2 * (i - 1) / rope_config.d_head) for i in range(1, rope_config.d_head // 2 + 1)]\n",
        "all_good = True\n",
        "for batch_idx in range(batch_size):\n",
        "    for m in range(seq_len):\n",
        "        if not all_good:\n",
        "            break\n",
        "        for head_idx in range(num_heads):\n",
        "            if not all_good:\n",
        "                break\n",
        "            for d_idx in range(d_head):\n",
        "                # 0, 2, 4\n",
        "                if d_idx % 2 == 0:\n",
        "                    val = x[batch_idx, m, head_idx, d_idx] * cos(m * thetas[d_idx // 2]) - x[batch_idx, m, head_idx, d_idx + 1] * sin(m * thetas[d_idx // 2])\n",
        "                else:\n",
        "                    val = x[batch_idx, m, head_idx, d_idx] * cos(m * thetas[d_idx // 2]) + x[batch_idx, m, head_idx, d_idx - 1] * sin(m * thetas[d_idx // 2])\n",
        "                if abs(y[batch_idx, m, head_idx, d_idx] - val) > 1e-3:\n",
        "                    print(f\"Ошибка на позиции {m} и размерности {d_idx} в голове {head_idx}\")\n",
        "                    print(f\"Полученное значение {y[batch_idx, m, head_idx, d_idx]}, референс {val}\")\n",
        "                    all_good = False\n",
        "                    break\n",
        "\n",
        "\n",
        "if all_good:\n",
        "    print(\"Тесты прошли успешно!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gknyVHKFAe-x"
      },
      "source": [
        "##  Attention masking - 3 балла\n",
        "\n",
        "Копируем имлементацию из предыдущего домашнего задания, но теперь нужно учесть и маски с паддингами.\n",
        "Для этого в `forward` и `apply_causal_mask` подана mask.\n",
        "\n",
        "В оригинальном задании 3 мы считали, что паддингов нет, поэтому делали маску нижней треугольной, чтобы токен i смотрел на токен j только тогда, когда `i >= j`, т.е. токен i мог смотреть все токены до него.\n",
        "\n",
        "Теперь же нужно сверх этого добавить еще и паддинг, т.е:\n",
        "\n",
        "1. Нам дается маска `[batch_size, seq_len]` из `collate_fn`. Напомню, что на позиции `[batch_idx, m]` стоит 1, если токен настоящий или 0, если это паддинг\n",
        "2. Мы должны модифицировать нашу нижнюю треугольную маску таким образом, чтобы не только не смотреть в будущее, но и не смотреть на паддинг.\n",
        "\n",
        "\n",
        "## Attention Rotary Embedding - 2 балла\n",
        "Также нужно вставить в attention слой роторные эмбеддинги:\n",
        "1. Нужно добавить их в init метод модели, в качестве theta можно оставить 10000\n",
        "2. Нужно применять их к матрицам Q, K перед матричным умножением $Q K^T$ в функции _get_qkv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_padding = torch.LongTensor([\n",
        "    [1, 1, 1, 1, 0, 0, 0],\n",
        "    [1, 1, 0, 0, 0, 0, 0],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]).to(device)\n",
        "attn_scores = torch.rand(batch_size, n_heads, seq_len, seq_len).to(device)\n",
        "attn_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLmeBorKm9Og",
        "outputId": "5e632c28-8ed5-4c91-d5f9-c00b975f5041"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masked_att_scores"
      ],
      "metadata": {
        "id": "JQ7ls-cJv6TS"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        mask_inf = torch.full_like(attn_scores, fill_value=-torch.inf)\n",
        "        tri_mask_inf = torch.triu(mask_inf, diagonal=1)\n",
        "\n",
        "        # создаем нижнетреульную матрицу c score\n",
        "        tri_attn_scores = torch.tril(attn_scores)\n",
        "\n",
        "        # формируем маску для паддингов\n",
        "        mask = mask_padding.unsqueeze(1).unsqueeze(-1).float()\n",
        "        mask_ = (mask == 0)\n",
        "        mask_padding = mask.masked_fill(mask_, value=-torch.inf)\n",
        "\n",
        "        masked_att_scores = tri_mask_inf + tri_attn_scores + mask_padding"
      ],
      "metadata": {
        "id": "oVKvLT5AvNfW"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        self.rope = RotaryPositionalEmbeddings(cfg=cfg, theta=10_000)\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(float(\"-inf\"), dtype=torch.float32, device=device))\n",
        "\n",
        "    def _get_qkv(\n",
        "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
        "    ) -> Tuple[Float[Tensor, \"batch seq_len num_heads d_head\"]]:\n",
        "        \"\"\"1. Трансформируем матрицы проекций в формат [d_model, d_model] и получаем проекции  Q, K, V\"\"\"\n",
        "        # Берем размерности\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "        num_heads = self.cfg.n_heads\n",
        "        d_head = self.cfg.d_head\n",
        "\n",
        "        W_Q = self.W_Q.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
        "        W_K = self.W_K.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
        "        W_V = self.W_V.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
        "\n",
        "        b_Q = self.b_Q.view(-1)\n",
        "        b_K = self.b_K.view(-1)\n",
        "        b_V = self.b_V.view(-1)\n",
        "\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        Q = x @ W_Q + b_Q\n",
        "        K = x @ W_K + b_K\n",
        "        V = x @ W_V + b_V\n",
        "\n",
        "        Q = Q.reshape(batch_size, seq_len, num_heads, d_head)\n",
        "        K = K.reshape(batch_size, seq_len, num_heads, d_head)\n",
        "        V = V.reshape(batch_size, seq_len, num_heads, d_head)\n",
        "\n",
        "        Q = self.rope(Q) # применяем rope\n",
        "        K = self.rope(K)\n",
        "\n",
        "        # не забудьте применить self.rotary после проекций!\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "        return Q, K, V\n",
        "\n",
        "    def _get_attention_dotprod(\n",
        "        self,\n",
        "        Q: Float[Tensor, \"batch seq_len num_heads d_head\"],\n",
        "        K: Float[Tensor, \"batch seq_len num_heads d_head\"]\n",
        "    ) -> Float[Tensor, \"batch num_heads seq_len seq_len\"]:\n",
        "        \"\"\"Q x K^T\"\"\"\n",
        "        # Ваш код здесь\n",
        "        d_head = self.cfg.d_head\n",
        "        num_heads = self.cfg.n_heads\n",
        "        d_head = self.cfg.d_head\n",
        "        seq_len = Q.shape[1]\n",
        "\n",
        "        K = K.permute(0, 2, 3, 1) # \"batch num_heads d_head  seq_len\"\n",
        "        Q = Q.permute(0, 2, 1, 3) # \"batch num_heads seq_len d_head\"\n",
        "\n",
        "        dotprod = Q @ K\n",
        "        return dotprod\n",
        "\n",
        "    def _get_attention_scores(\n",
        "        self,\n",
        "        attention_scores: Float[Tensor, \"batch num_heads seq_len seq_len\"],\n",
        "        mask: Int[Tensor, \"batch seq_len\"]\n",
        "    ) -> Float[Tensor, \"batch num_heads seq_len seq_len\"]:\n",
        "        \"\"\"Нормализация, маскирование и softmax\"\"\"\n",
        "        # ---- Ваш код здесь ----\n",
        "        d_head = self.cfg.d_head\n",
        "        masked_att_scores = self.apply_causal_mask(attention_scores, mask) # batch n_heads seq_len seq_len\n",
        "        attn_probs = torch.softmax(masked_att_scores / (d_head)**0.5, dim=-1)\n",
        "        return attn_probs\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "    def _get_final_projection(\n",
        "        self,\n",
        "        V: Float[Tensor, \"batch seq_len num_heads d_head\"],\n",
        "        attn_probs: Float[Tensor, \"batch num_heads seq_len seq_len\"]\n",
        "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
        "        \"\"\"Финальная проекция\n",
        "        permute [ batch, num_heads, seq_len, d_head]\"\"\"\n",
        "        batch_size, seq_len = V.shape[0], V.shape[1]\n",
        "        d_model = self.cfg.d_model\n",
        "        num_heads = self.cfg.n_heads\n",
        "        d_head = self.cfg.d_head\n",
        "\n",
        "        premute_V = V.permute(0, 2, 1, 3) # --> (batch num_heads seq_len d_head)\n",
        "\n",
        "        res = attn_probs @ premute_V # (batch num_heads seq_len seq_len) * (batch num_heads seq_len d_head) -->  (batch num_heads seq_len d_head)\n",
        "        res = res.permute(0, 2, 1, 3).reshape(batch_size, seq_len, num_heads * d_head) # (batch seq_len d_model)\n",
        "        # Ваш код здесь\n",
        "        return res @ self.W_O.reshape(d_model, d_model)  + self.b_O # (batch seq_len d_model) * (n_heads, d_head, d_model) --> (batch seq_len d_model)\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch seq_len d_model\"],  mask: Int[Tensor, \"batch seq_len\"]\n",
        "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
        "        # 1. получаем проекции  Q, K, V\n",
        "        Q, K, V = self._get_qkv(x)\n",
        "        # 2. Q x K^T\n",
        "        attention_scores = self._get_attention_dotprod(Q, K)\n",
        "\n",
        "        # 3. Нормализация, маскирование и softmax\n",
        "        attn_probs = self._get_attention_scores(attention_scores, mask)\n",
        "\n",
        "        # 6. Финальная проекция\n",
        "        # permute [ batch, num_heads, seq_len, d_head]\n",
        "        res = self._get_final_projection(V, attn_probs)\n",
        "        return res\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads seq_len seq_len\"], mask: Int[Tensor, \"batch seq_len\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads seq_len seq_len\"]:\n",
        "        '''\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        Используем треугольную маску, чтобы не смотреть в будущее!\n",
        "        В качестве масикировочного значения перед софтмаксом можно использовать self.IGNORE (-inf)\n",
        "\n",
        "        В дополнение к предыдущему заданию используйте аргумент mask, чтобы не смотреть не только на будущие токены,\n",
        "        но и на паддинги.\n",
        "        Сами паддинги могут смотреть на любые токены.\n",
        "        '''\n",
        "        seq_len = mask.size(1)\n",
        "        # ---- Ваш код здесь ----\n",
        "        # создаем верхнетреугольную матрицу с inf\n",
        "        mask_inf = torch.full_like(attn_scores, fill_value=self.IGNORE)\n",
        "        tri_mask_inf = torch.triu(mask_inf, diagonal=1)\n",
        "\n",
        "        # создаем нижнетреульную матрицу c score\n",
        "        tri_attn_scores = torch.tril(attn_scores)\n",
        "\n",
        "        # формируем маску для паддингов\n",
        "        mask = mask.unsqueeze(1).unsqueeze(-2).float()\n",
        "        mask_ = (mask == 0)\n",
        "        mask_padding = mask.masked_fill(mask_, value=-torch.inf)\n",
        "\n",
        "        masked_att_scores = tri_mask_inf + tri_attn_scores + mask_padding\n",
        "\n",
        "        return masked_att_scores\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "mask_padding = torch.LongTensor([\n",
        "    [1, 1, 1, 1, 0, 0, 0],\n",
        "    [1, 1, 0, 0, 0, 0, 0],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]).to(device)\n",
        "\n",
        "lengths = mask_padding.sum(dim=1).tolist()\n",
        "\n",
        "\n",
        "batch_size = 3\n",
        "seq_len = 7\n",
        "d_head = 8\n",
        "n_heads = 4\n",
        "torch.manual_seed(1)\n",
        "x = torch.rand(batch_size, n_heads, seq_len, seq_len).to(device)\n",
        "\n",
        "attn = Attention(cfg).to(device)\n",
        "softmax_res = torch.softmax(attn.apply_causal_mask(x, mask_padding), dim=-1)\n",
        "\n",
        "for batch_idx in range(batch_size):\n",
        "    for head_idx in range(n_heads):\n",
        "        sm = softmax_res[batch_idx, head_idx]\n",
        "        l = lengths[batch_idx]\n",
        "        for i in range(seq_len):\n",
        "            for j in range(seq_len):\n",
        "                # i < j - Causal mask, проверяем, что не смотрим в будущее!\n",
        "                # j >= l - проверяем, что не смотрим на паддинги!\n",
        "                if i < j or j >= l:\n",
        "                    assert sm[i, j] == 0, (batch_idx, head_idx, i, j, sm[i, j])\n",
        "\n",
        "_ = attn(torch.rand(batch_size, seq_len, 768).to(device), mask_padding.to(device))\n",
        "print(\"All good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlUuTFwemWWk",
        "outputId": "afa5b6a6-751d-4ae4-bd91-0dac0f9d2032"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_TzTaPNAe-x"
      },
      "source": [
        "## Собираем Transformer - 5\n",
        "\n",
        "1. В TransformerBlock и DemoTransformer немного модифицируем код из предыдущего задания, чтобы передавать mask в слои аттеншена.\n",
        "2. Не используем позиционные эмбеддинги, т.к. кодирование позиционной информации уже заложено в роторные эмбеддинги, которые являются частью attention слоя\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "Oct8-IpcAe-x"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = RMSNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = RMSNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch seq_len d_model\"], mask: Float[Tensor, \"batch seq_len\"]\n",
        "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
        "        # ---- Ваш код здесь ----\n",
        "        # raise NotImplemented()\n",
        "        # ---- Конец кода ----\n",
        "        x = x + self.attn(self.ln1(x), mask)\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = RMSNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"], mask: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
        "        # ---- Ваш код здесь ----\n",
        "        # raise NotImplemented()\n",
        "        # ---- Конец кода ----\n",
        "        x = self.embed(input_ids)\n",
        "        for block in self.blocks:\n",
        "            x = block(x, mask)\n",
        "        x = self.unembed(self.ln_final(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "ukRTkqa1Ae-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee29c5ca-21bb-4c1e-8367-dcdfa0bf1946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all good\n"
          ]
        }
      ],
      "source": [
        "train_config = Config(\n",
        "    d_model=128,\n",
        "    n_ctx=512,\n",
        "    n_heads=8,\n",
        "    d_head=16,\n",
        "    d_mlp=512,\n",
        "    n_layers=12\n",
        ")\n",
        "model = DemoTransformer(train_config).to(device)\n",
        "\n",
        "for input_ids, mask in train_loader:\n",
        "    break\n",
        "\n",
        "p = model(input_ids.to(device), mask.to(device))\n",
        "\n",
        "\n",
        "assert list(p.shape) == [input_ids.size(0), input_ids.size(1), train_config.d_vocab]\n",
        "p.sum().backward()\n",
        "\n",
        "del model\n",
        "del p\n",
        "print(\"all good\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf4pHJPoAe-y"
      },
      "source": [
        "# Обучение - 15 баллов\n",
        "\n",
        "## calculate_loss - 5\n",
        "\n",
        "Здесь нужно написать обычный training loop. Вначале напишем функцию для подсчета функции потерь `calculate_loss`. Функция принимает выходы модели logits размерности \\[batch_size, seq_len, vocab_size\\], input_ids размерности \\[batch_size, seq_len\\] и attention_mask размерности \\[batch_size, seq_len\\].\n",
        "\n",
        "Так как мы хотим учиться на задаче языкового моделирования, в logits на позиции \\[i, j\\] находится распределение токенов по словарю для токена на позиции \\[i, j + 1\\] (мы предсказываем следующий токен). Каждое такое предсказание следующего токена мы будем рассматривать как задачу классификации и учить с помощью кроссэнтропийной функции потерь.\n",
        "\n",
        "Алгоритм:\n",
        "1. Обрезаем logits по размерности seq_len справа на 1: последний токен на позиции N у нас предсказывает токен на позиции N + 1, однако (N + 1)-го токена у нас нет, поэтому использовать эти предсказания для обучения мы не сможем.\n",
        "2. Заводим переменную labels - для этого обрезаем input_ids слева на 1. Это будет наш массив меток. Мы обрезаем его слева на 1 по размерности seq_len, т.е. по сути сдвигагем этот массив таким образом, что на j-й позиции теперь стоит (j + 1)-й токен. Это очень важно для подсчета функции потерь, т.к. мы предсказываем следующий токен\n",
        "3. Аналогично labels обрезаем attention_mask и переводим маску в `.bool()`\n",
        "4. На позициях, где attention_mask == 0 (паддинги) проставляем в labels значение -100. Это дефолтное значение [ignore_index](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) из кроссэнтропийной функции потерь, означающее, что для этой метки не будет считаться функция потерь. Таким образом мы не будем учиться предсказывать паддинги\n",
        "5. Объеднияем в logits и labels размерности batch и seqlen с помощью view и подаем это в кроссэнтропийную функцию потерь, считаем loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "q7pAO0SdAe-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b0eda6-0223-47d8-d392-3607f059e370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.934269905090332\n"
          ]
        }
      ],
      "source": [
        "from math import log\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "pad_id = tokenizer.pad_token_id\n",
        "\n",
        "def calculate_loss(logits, input_ids, attention_mask):\n",
        "    labels = input_ids.detach().clone()\n",
        "    # ---- Ваш код здесь ----\n",
        "    # raise NotImplemented()\n",
        "    # ---- Конец кода ----\n",
        "    labels = labels[:, 1:]\n",
        "    attention_mask = attention_mask[:, 1:].bool()\n",
        "    labels[~attention_mask] = -100\n",
        "\n",
        "    logits = logits[:, :-1]\n",
        "\n",
        "    loss = criterion(logits.reshape(-1, logits.size(-1)), labels.reshape(-1))\n",
        "    return loss\n",
        "\n",
        "batch_size = 2\n",
        "seq_len = 4\n",
        "num_classes = 7\n",
        "\n",
        "input_ids = torch.LongTensor(\n",
        "    [\n",
        "        [0, 1,  pad_id, pad_id],\n",
        "        [0, 1, 2, 3]\n",
        "    ]\n",
        ")\n",
        "\n",
        "attention_mask = torch.LongTensor(\n",
        "    [\n",
        "        [1, 1, 0, 0],\n",
        "        [1, 1, 1, 1]\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# batch_size, seq_len, num_classes\n",
        "logits = torch.Tensor(\n",
        "    [[[0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999, 0.3971],\n",
        "         [0.7544, 0.5695, 0.4388, 0.6387, 0.5247, 0.6826, 0.3051],\n",
        "         [0.4635, 0.4550, 0.5725, 0.4980, 0.9371, 0.6556, 0.3138],\n",
        "         [0.1980, 0.4162, 0.2843, 0.3398, 0.5239, 0.7981, 0.7718]],\n",
        "\n",
        "        [[0.0112, 0.8100, 0.6397, 0.9743, 0.8300, 0.0444, 0.0246],\n",
        "         [0.2588, 0.9391, 0.4167, 0.7140, 0.2676, 0.9906, 0.2885],\n",
        "         [0.8750, 0.5059, 0.2366, 0.7570, 0.2346, 0.6471, 0.3556],\n",
        "         [0.4452, 0.0193, 0.2616, 0.7713, 0.3785, 0.9980, 0.9008]]]\n",
        ")\n",
        "logits.requires_grad=True\n",
        "\n",
        "loss = calculate_loss(logits, input_ids, attention_mask)\n",
        "\n",
        "assert abs(loss.item() - 1.934269905) < 1e-3\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9hRKcXNFSBb"
      },
      "source": [
        "## Training loop - 5\n",
        "\n",
        "\n",
        "Давайте теперь напишем training loop:\n",
        "1. Перемещаем input_ids и mask на правильный device\n",
        "2. Зануляем градиенты модели\n",
        "3. Считаем выходы модели (logits)\n",
        "4. Считаем функцию потерь с помощью функции calculate_loss\n",
        "5. Делаем backward и обновляем веса оптимизатором\n",
        "\n",
        "Учить модель лучше 10+ эпох.\n",
        "\n",
        "Также предлагается добавлять значения функции потерь в массив losses, чтобы изобразить её изменения в следующей клетке на графике"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy8_eXGEAe-y"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = DemoTransformer(cfg).to(device)\n",
        "\n",
        "model = model.train()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(15):\n",
        "    for input_ids, mask in tqdm(train_loader):\n",
        "        # 1. перемещаем входы на device\n",
        "        input_ids = input_ids.to(device)\n",
        "        mask = mask.to(device)\n",
        "        # ---- Ваш код здесь ----\n",
        "        # 2. Обнуляем градиенты\n",
        "        ...\n",
        "        # 3. Считаем выходы модели\n",
        "        ...\n",
        "        # 4. считаем функцию потерь\n",
        "        loss = ...\n",
        "        # 5. Делаем backward и шаг оптимизации\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        # ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ezat1yvAe-y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN08MGaBAe-y"
      },
      "source": [
        "## Генерация - 5 баллов\n",
        "Давайте теперь попробуем посмотреть, что у нас обучилось! Для этого проверим себя на жадной генерации.\n",
        "\n",
        "Для этого:\n",
        "1. Подаем входы в модель\n",
        "2. Берем последний элемент в logits по размерности seq_len и argmax по нему. Это сгенерированный токен, полученный жадным сэмплингом.\n",
        "3. Конкатенируем его ко входам, конкатенируем \\[\\[1\\]\\] в маску\n",
        "4. Генерируем так 30 токенов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcayBMRkAe-y"
      },
      "outputs": [],
      "source": [
        "input_text = text[:13]\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "input_ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "orig_size = input_ids.size(1)\n",
        "\n",
        "num_tokens_to_generate = 30\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(num_tokens_to_generate):\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        logits = ...\n",
        "        next_token = ...\n",
        "        input_ids = ...\n",
        "        mask = ...\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "print(\"Input text:\\n\", input_text)\n",
        "print()\n",
        "print(\"Generated text:\\n\", tokenizer.decode(input_ids[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFhyAmAPAe-y"
      },
      "source": [
        "Если все прошло успешно, то мы увидим какой-то небольшой, возможно,  повторяющийся текст. Смысла в нем скорее всего будет немного, но издалека он будет выглядеть вполне реалистично.\n",
        "\n",
        "Осталось отмашстабировать модель, накинуть данных и получится настоящий pretrain!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4551b35eb7a846909a713e2c8ca94d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8fa3fb64d2d40fea0bde0d04700f94d",
              "IPY_MODEL_70002f9acc544a27a453f7324d2e6e6d",
              "IPY_MODEL_007f4be422f842eea3e64b6ab483e34d"
            ],
            "layout": "IPY_MODEL_9e533448953f4f6a9ae7df8059b5ac38"
          }
        },
        "c8fa3fb64d2d40fea0bde0d04700f94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef40650ffc6248beaa6bc925d9e75023",
            "placeholder": "​",
            "style": "IPY_MODEL_c04cf57ba2b1444d9e10779a8376bb5f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "70002f9acc544a27a453f7324d2e6e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_196848efa3e946878d340b078e8cf42d",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f20eec2ba4c04b68b03ce95f1150a36a",
            "value": 26
          }
        },
        "007f4be422f842eea3e64b6ab483e34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a81c91b855484378ae7acaeb695a89c2",
            "placeholder": "​",
            "style": "IPY_MODEL_d340aa9c6c4e441aae2936eef7ee2076",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.57kB/s]"
          }
        },
        "9e533448953f4f6a9ae7df8059b5ac38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef40650ffc6248beaa6bc925d9e75023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04cf57ba2b1444d9e10779a8376bb5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196848efa3e946878d340b078e8cf42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20eec2ba4c04b68b03ce95f1150a36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a81c91b855484378ae7acaeb695a89c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d340aa9c6c4e441aae2936eef7ee2076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fa1059503274060a8470478c0592d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a50b562a2b734d2a98708fa2551d27c0",
              "IPY_MODEL_65a32cc969104cd99c3968e240cb404a",
              "IPY_MODEL_b02ae3df46d24d288583dff04477ec6a"
            ],
            "layout": "IPY_MODEL_6622c34237464a84a6eaefaf2a10a360"
          }
        },
        "a50b562a2b734d2a98708fa2551d27c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2dfb19c2cf345f28dc24cb479b6f622",
            "placeholder": "​",
            "style": "IPY_MODEL_7963308e0c84484ba1211fd2a7d65a4f",
            "value": "config.json: 100%"
          }
        },
        "65a32cc969104cd99c3968e240cb404a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07889b1d54074bfea36408785f62b6c6",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac4ef159619b4349ba5e9c8cfa7937a4",
            "value": 665
          }
        },
        "b02ae3df46d24d288583dff04477ec6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4abae0b6704ca581267290aec95962",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd6fb0bf06042b692541f70dda450b0",
            "value": " 665/665 [00:00&lt;00:00, 53.6kB/s]"
          }
        },
        "6622c34237464a84a6eaefaf2a10a360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2dfb19c2cf345f28dc24cb479b6f622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7963308e0c84484ba1211fd2a7d65a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07889b1d54074bfea36408785f62b6c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4ef159619b4349ba5e9c8cfa7937a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f4abae0b6704ca581267290aec95962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd6fb0bf06042b692541f70dda450b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd8ad11268246aaab7f7571a0b34255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36286884ccf648beb98012e2828bd488",
              "IPY_MODEL_cbc49c64ce7646e483241d75dadba1a3",
              "IPY_MODEL_e305875fdcfa4544a157c626d0702ca5"
            ],
            "layout": "IPY_MODEL_2f024b9a303849dba451e68fe65cfb49"
          }
        },
        "36286884ccf648beb98012e2828bd488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_350d1a6e303441c1948ccd13951e016c",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ddd4c6460b476593c4a19055a17575",
            "value": "vocab.json: 100%"
          }
        },
        "cbc49c64ce7646e483241d75dadba1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497cbcd021ad4f4480ec66aa94cadf1f",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81113f01de294615a90e3a30422940ad",
            "value": 1042301
          }
        },
        "e305875fdcfa4544a157c626d0702ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d51cb362704ed8a2d10e5174d88148",
            "placeholder": "​",
            "style": "IPY_MODEL_f111d8ebccfb45fea39f643f2c5b0784",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.95MB/s]"
          }
        },
        "2f024b9a303849dba451e68fe65cfb49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "350d1a6e303441c1948ccd13951e016c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ddd4c6460b476593c4a19055a17575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497cbcd021ad4f4480ec66aa94cadf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81113f01de294615a90e3a30422940ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01d51cb362704ed8a2d10e5174d88148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f111d8ebccfb45fea39f643f2c5b0784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f1211d5b170469fbe0f13be94729541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d8a6be97b443f1b0fc9c1516b80c2e",
              "IPY_MODEL_ae99f81d45b3494ea4bee7f94767246e",
              "IPY_MODEL_7a0dc3b6780243239cb35af68b4b1517"
            ],
            "layout": "IPY_MODEL_32817f032ed049feace817adb4d8dc5b"
          }
        },
        "b5d8a6be97b443f1b0fc9c1516b80c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b1fc4b066948329ef600f1988fe4f6",
            "placeholder": "​",
            "style": "IPY_MODEL_409cff701a0b41ce8832a4e07591a3e0",
            "value": "merges.txt: 100%"
          }
        },
        "ae99f81d45b3494ea4bee7f94767246e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ae005f24ca4162a69289eb9c8c0325",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5c1e02972d74e2e9e9304841ec3830d",
            "value": 456318
          }
        },
        "7a0dc3b6780243239cb35af68b4b1517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee0a60fd5084151b78e1c7c4669ed29",
            "placeholder": "​",
            "style": "IPY_MODEL_20eff29063bb4362aa3312cf71886d37",
            "value": " 456k/456k [00:00&lt;00:00, 2.97MB/s]"
          }
        },
        "32817f032ed049feace817adb4d8dc5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b1fc4b066948329ef600f1988fe4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409cff701a0b41ce8832a4e07591a3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ae005f24ca4162a69289eb9c8c0325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c1e02972d74e2e9e9304841ec3830d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cee0a60fd5084151b78e1c7c4669ed29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20eff29063bb4362aa3312cf71886d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63151483bdaf45b1af907be532312df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed9b8175f42e4a50b8490ec92c36bda7",
              "IPY_MODEL_a56e76795b5347ddba8971d899a89340",
              "IPY_MODEL_bb9e9f52f59c4b929c2a4ebdb7839205"
            ],
            "layout": "IPY_MODEL_928ff9cb73c946478e3d11748672230f"
          }
        },
        "ed9b8175f42e4a50b8490ec92c36bda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c87741f297942d5b78d39c5e6e7328e",
            "placeholder": "​",
            "style": "IPY_MODEL_bf9e82197e914ab3a78a1e380fc95ccc",
            "value": "tokenizer.json: 100%"
          }
        },
        "a56e76795b5347ddba8971d899a89340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88a9c9c533e4419e8c30540785721049",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ee015106ca24a1aa8b7ab12b92dc67e",
            "value": 1355256
          }
        },
        "bb9e9f52f59c4b929c2a4ebdb7839205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2185978ef8b48759eca387b5f50c84c",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9e6dfea6d2489597eafe386b89e1ba",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.51MB/s]"
          }
        },
        "928ff9cb73c946478e3d11748672230f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c87741f297942d5b78d39c5e6e7328e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf9e82197e914ab3a78a1e380fc95ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88a9c9c533e4419e8c30540785721049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee015106ca24a1aa8b7ab12b92dc67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2185978ef8b48759eca387b5f50c84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9e6dfea6d2489597eafe386b89e1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}