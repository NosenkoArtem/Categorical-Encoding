{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NosenkoArtem/Categorical-Encoding/blob/master/%D0%94%D0%97_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 2"
      ],
      "metadata": {
        "id": "gY02gGgISkjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1. Неявный метод оценивания score-функции\n",
        "\n",
        "На лекции мы обсудили методолгоию score matching, где функция потерь для обучения градиента логарифма плотности данных представляется как\n",
        "$$\n",
        "    \\frac{1}{2} \\mathbb{E}_{\\pi}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}) - \\nabla_\\mathbf{x} \\log \\pi(\\mathbf{x}) \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}.\n",
        "$$\n",
        "\n",
        "\n",
        "В частности, мы познакомились с выводом **implicit score matching**.\n",
        "\n",
        "Напомним, что функция потерь для обучения  **implicit score matching** выражается так:\n",
        "$$\n",
        "\\frac{1}{2} \\mathbb{E}_{\\pi}\\bigl\\| s_{\\boldsymbol{\\theta}}(x) - \\nabla_x \\log \\pi(x) \\bigr\\|^2_2 = \\mathbb{E}_{\\pi}\\left[ \\frac{1}{2}s^2_{\\boldsymbol{\\theta}}(x) + \\nabla_{x} s_{\\boldsymbol{\\theta}}(x) \\right] + \\text{const}.\n",
        "$$\n",
        "\n",
        "В данном задании вам необходимо ответить на следующие вопросы:\n",
        "\n",
        "- Почему выражение справа в последней формуле с точки зрения практики лучше для нас, чем выражение слева?  \n",
        "\n",
        "- По каким причинам мы не пользуемся данной методологией **implicit score matching** и обращаемся к **denoising score matching** ?\n",
        "\n",
        "- Повторите вывод из лекции для **implicit score matching** в одномерном случае."
      ],
      "metadata": {
        "id": "CHWeqF32Srot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc2R5RVzScUA"
      },
      "outputs": [],
      "source": [
        "# your latex code is here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 2. Марковские цепи\n",
        "\n",
        "Пусть последовательность $X_{0},...,X_{T}$ образует марковскую цепь. Покажите, что обратная по времени последовательность $X_{T},...,X_{0}$ тоже является марковской цепью, то есть:\n",
        "\n",
        "$$ p_{X_{t-1}|X_{t},...,X_{T}}(x_{t-1}|x_{t},...,x_{T}) = p_{X_{t-1}|X_{t}}(x_{t-1}|x_{t}) .$$"
      ],
      "metadata": {
        "id": "eJyRpG77mJnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your latex code is here"
      ],
      "metadata": {
        "id": "WnW1_hKPmnIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 3. Зашумленный метод оценивания score-функции для двумерных данных\n",
        "\n",
        "В данной задаче вам предстоит дописать недостающие элементы в коде. Стоит отметить, что данная реализация не совсем такая, как в семинаре, и сделано это специально, чтобы вы не просто взяли код из семинара, а смогли и сами написать все необходимые блоки."
      ],
      "metadata": {
        "id": "we5uTnaFUbAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускать данный метод **denoising score matching** будем  на датасете лун, который выглядит так, как на картинке ниже.\n",
        "\n",
        "Тогда давайте напишем функцию, которая создает такой датасет.\n",
        "\n",
        "![title](https://i2.wp.com/miro.medium.com/1*itR36uLRt36bmFQVh-cVtQ.jpeg)"
      ],
      "metadata": {
        "id": "HzVkxTwbVM2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала импортируем необходимые библиотеки. А уже потом заводим функцию **generate_moons_data**, которая возвращает нам данные, располагающиеся в виде лун."
      ],
      "metadata": {
        "id": "cOHwU14wnHRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from typing import List, Tuple\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "jYYHWrotXbRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_moons_data(count: int) -> tuple:\n",
        "    data, labels = make_moons(n_samples=count, noise=0.1)\n",
        "    data = data.astype(\"float32\")\n",
        "    split = int(0.8 * count)\n",
        "    train_data, test_data = data[:split], data[split:]\n",
        "    train_labels, test_labels = labels[:split], labels[split:]\n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "metadata": {
        "id": "gB7Tny04VgxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмем 5000 точек для визуализации данных:"
      ],
      "metadata": {
        "id": "fmcEcFfOnXyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COUNT = 5000\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = generate_moons_data(COUNT)"
      ],
      "metadata": {
        "id": "8I2N8mdhVix6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте вспомним теорию.  \n",
        "\n",
        "\n",
        "Идея заключается в следующем. Мы определяем score-функцию\n",
        "$$\n",
        "    \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\nabla_{\\mathbf{x}}\\log p(\\mathbf{x}| \\boldsymbol{\\theta}).\n",
        "$$\n",
        "\n",
        "Наша основная задача состоит в том, что нам хотелось бы минимизировать дивергенцию Фишера, чтобы получить score-функцию:\n",
        "$$\n",
        "    D_F(\\pi, p) = \\frac{1}{2}\\mathbb{E}_{\\pi}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}) - \\nabla_{\\mathbf{x}} \\log \\pi(\\mathbf{x}) \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}.\n",
        "$$\n",
        "\n",
        "И если нам бы удалось оценить score-функцию, то мы могли бы использовать динамику Ланжевена для генерации выборки из необходимого распределения:\n",
        "$$\n",
        "    \\mathbf{x}_{l + 1} = \\mathbf{x}_l + \\frac{\\eta}{2} \\cdot \\nabla_{\\mathbf{x}_l} \\log p(\\mathbf{x}_l | \\boldsymbol{\\theta}) + \\sqrt{\\eta} \\cdot \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\mathbf{I}).\n",
        "$$\n",
        "\n",
        "Однако дивергенция Фишера трудноразрешима (так как мы не знаем честную score-функцию), и мы используем процедуру добавления шума **denoising score matching**  для оценки score-функции по зашумленным данным $$\\mathbf {x}_{\\sigma} = \\mathbf {x} + \\sigma \\cdot \\boldsymbol{\\epsilon}.$$\n",
        "\n",
        "Как мы выяснили на лекции, минимизация дивергенции Фишера для зашумленных данных эквивалентна следующей задаче:\n",
        "\\begin{multline*}\n",
        "    \\mathbb{E}_{q(\\mathbf{x}_{\\sigma})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma}(\\mathbf{x}_{\\sigma}) - \\nabla_{\\mathbf{x}_{\\sigma}} \\log q(\\mathbf{x}_{\\sigma}) \\bigr\\|^2_2\n",
        "    = \\mathbb{E}_{\\pi(\\mathbf{x})} \\mathbb{E}_{q(\\mathbf{x}_{\\sigma} | \\mathbf{x})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma}(\\mathbf{x}_{\\sigma}) - \\nabla_{\\mathbf{x}_{\\sigma}} \\log q(\\mathbf{x}_{\\sigma} | \\mathbf{x}) \\bigr\\|^2_2 + \\text{const}(\\boldsymbol{\\theta}).\n",
        "\\end{multline*}\n",
        "\n",
        "Здесь\n",
        "$$\n",
        "    \\log q(\\mathbf{x}_{\\sigma} | \\mathbf{x}) = - \\frac{\\mathbf{x}_{\\sigma} - \\mathbf{x}}{\\sigma^2} = - \\frac{\\boldsymbol{\\epsilon}}{\\sigma}.\n",
        "$$\n",
        "\n",
        "Тогда финальная формула для denoising score matching это\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_{\\pi(\\mathbf{x})} \\mathbb{E}_{q(\\mathbf{x}_{\\sigma} | \\mathbf{x})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma}(\\mathbf{x}_{\\sigma}) + \\frac{\\boldsymbol{\\epsilon}}{\\sigma} \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}.\n",
        "$$"
      ],
      "metadata": {
        "id": "h6zJJf4wVxaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenoisingScoreMatcher(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            score_model: nn.Module,\n",
        "            input_shape: Tuple[int],\n",
        "            sigma: float\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.score_model = score_model\n",
        "        self.input_shape = input_shape\n",
        "        self.sigma = sigma\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # ====\n",
        "        # your code\n",
        "        # написать, как семплируется гауссовский шум\n",
        "        # получить зашумленные данные через исходные и шум\n",
        "        noisy_x =\n",
        "        # =====\n",
        "\n",
        "        # посчитать score-функцию для зашумленных данных\n",
        "        s = self.score_model(noisy_x)\n",
        "\n",
        "        # ====\n",
        "        # your code\n",
        "        # запишите функцию потерь метода\n",
        "        # это МСЕ Loss\n",
        "\n",
        "        # =====\n",
        "        return loss\n",
        "\n",
        "    def loss(self, x: torch.Tensor):\n",
        "        return {\"total_loss\": self(x).mean(dim=0).sum()}\n",
        "\n",
        "    def langevin_dynamics(self, x: torch.Tensor, num_steps: int, eta: float):\n",
        "        # =====\n",
        "        # your code\n",
        "        # Запишите итеративную процедуру динамики Ланжевена\n",
        "\n",
        "        # =====\n",
        "        return x\n",
        "\n",
        "    def sample(self, num_samples: int = 64, num_steps: int=100, eta: float = 0.01):\n",
        "        with torch.no_grad():\n",
        "            # мы семплируем x_0 из равномерного распределения на отрезке U[-1, 1]\n",
        "            x0 = 2. * torch.rand_like(torch.empty(num_samples, *self.input_shape)) - 1.\n",
        "            x0 = x0.to(self.device)\n",
        "\n",
        "            # запустить динамику Ланжевена\n",
        "            x = self.langevin_dynamics(x0, num_steps=num_steps, eta=eta)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_denoiser_score_matcher():\n",
        "    matcher = DenoisingScoreMatcher(\n",
        "        score_model=nn.Linear(2, 2),\n",
        "        input_shape=(2,),\n",
        "        sigma=0.1\n",
        "    )\n",
        "    x = torch.rand(16, 2)\n",
        "    assert x.size() == matcher(x).size()\n",
        "    loss = matcher.loss(x)[\"total_loss\"]\n",
        "    assert len(loss.size()) == 0\n",
        "    assert list(matcher.sample(4).size()) == [4, 2]\n",
        "\n",
        "\n",
        "test_denoiser_score_matcher()"
      ],
      "metadata": {
        "id": "4dKfylyNWsiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====\n",
        "# your code\n",
        "# Выберите гиперпараметры метода\n",
        "\n",
        "BATCH_SIZE =\n",
        "EPOCHS =   # > 50\n",
        "LR =   # > 1e-3\n",
        "HIDDEN_SIZE =   # > 32\n",
        "SIGMA =  # 0.01 < x < 1.0\n",
        "# ====\n",
        "\n",
        "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# ====\n",
        "# your code\n",
        "# определите архитектуру модели, смотрите семинар 2\n",
        "#\n",
        "score_model =\n",
        "# ====\n",
        "\n",
        "matcher = DenoisingScoreMatcher(\n",
        "    score_model=score_model, input_shape=(2,), sigma=SIGMA\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(matcher.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "49dDkM20Wt4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также вам необходимо описать функцию тренировки данной модели и запустить ее."
      ],
      "metadata": {
        "id": "6UQQ3z2wW5c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train_model(\n",
        "    matcher,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=EPOCHS,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=DEVICE,\n",
        "    n_samples=512):\n",
        "\n",
        "\n",
        "  # и теперь, определив саму модель, необходимо написать самый базовый торчовский цикл обучения модели\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d3TeigrfW5m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уже обученную модель matcher можно запустить и посмотреть, какие семплы она воспроизводит."
      ],
      "metadata": {
        "id": "_LWiF_RmXhp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====\n",
        "# your code\n",
        "# выберите параметры для семплирования динамикой Ланжевена\n",
        "NUM_STEPS =\n",
        "ETA =\n",
        "# ====\n",
        "\n",
        "samples = matcher.sample(num_samples=5000, num_steps=NUM_STEPS, eta=ETA).cpu()"
      ],
      "metadata": {
        "id": "lHBrwv3FXndc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишите полученные вами изображения."
      ],
      "metadata": {
        "id": "Spl6U8AipcnJ"
      }
    }
  ]
}