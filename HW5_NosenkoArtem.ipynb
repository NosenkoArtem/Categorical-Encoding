{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMyvOO4mja1Qx30rKON3MB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NosenkoArtem/Categorical-Encoding/blob/master/HW5_NosenkoArtem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Импорты библиотек"
      ],
      "metadata": {
        "id": "DY9BtuJjd8Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kapV5MNOeByV",
        "outputId": "3645e56e-e23d-4aa3-cf45-820ba8d358ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'peft'...\n",
            "remote: Enumerating objects: 10700, done.\u001b[K\n",
            "remote: Counting objects: 100% (1702/1702), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 10700 (delta 1585), reused 1468 (delta 1466), pack-reused 8998 (from 3)\u001b[K\n",
            "Receiving objects: 100% (10700/10700), 14.14 MiB | 17.47 MiB/s, done.\n",
            "Resolving deltas: 100% (7357/7357), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./peft/examples/lora_dreambooth/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sdLSfNJeErN",
        "outputId": "cf1b58d8-8a59-4ee3-a4b6-524cff1354b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (4.48.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (1.3.0)\n",
            "Collecting evaluate (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 3))\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 4)) (4.67.1)\n",
            "Collecting datasets (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 5))\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 6)) (0.32.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 8)) (0.20.1+cu124)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 10)) (0.5.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (0.19.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (0.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (2.5.1+cu124)\n",
            "Collecting dill (from evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3))\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3)) (2.2.2)\n",
            "Collecting xxhash (from evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (17.0.0)\n",
            "Collecting dill (from evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (3.11.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 6)) (8.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (2.21.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r ./peft/examples/lora_dreambooth/requirements.txt (line 5)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->-r ./peft/examples/lora_dreambooth/requirements.txt (line 6)) (3.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r ./peft/examples/lora_dreambooth/requirements.txt (line 11)) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate->-r ./peft/examples/lora_dreambooth/requirements.txt (line 2)) (3.0.2)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed datasets-3.3.0 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import wandb\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwM9HLYkeLUI",
        "outputId": "c612d3aa-540a-4ca0-e9b9-d78af2105ee9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR = '/content/drive/MyDrive/dino'\n",
        "\n",
        "PATH_IMAGES = '/content/drive/MyDrive/dino/imgs'\n",
        "PATH_PROMPT = '/content/drive/MyDrive/dino/train.csv'\n",
        "PATH_DREAMBOOTH = '/content/drive/MyDrive/dreambooth/train_dreambooth.py'\n",
        "PATH_OUTPUT = '/content/drive/MyDrive/dino/output'\n",
        "\n",
        "WANDB_API_KEY= '/content/drive/MyDrive/ssh/wandbkey.txt'\n",
        "\n",
        "with open(WANDB_API_KEY, 'r') as file:\n",
        "    wandb_key = file.read().strip()"
      ],
      "metadata": {
        "id": "-Eja2dUDepqE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# для colab не работает :(\n",
        "os.environ['PATH_DREAMBOOTH'] = PATH_DREAMBOOTH\n",
        "os.environ['PATH_IMAGES'] = PATH_IMAGES\n",
        "os.environ['PATH_OUTPUT'] = PATH_OUTPUT\n",
        "os.environ['PATH_PROMPT'] = PATH_PROMPT\n",
        "os.environ['WANDB_KEY'] = WANDB_API_KEY"
      ],
      "metadata": {
        "id": "jzoyO_X-Kxwf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=wandb_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoV8obdX4SBw",
        "outputId": "381dd783-8a59-4164-f9fd-2bf6de12a284"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnosenkoartyom1989\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    # Set the project where this run will be logged\n",
        "    project=\"stickers\",\n",
        "    # Track hyperparameters and run metadata\n",
        "    config={},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "tRd1B9LcfZ-1",
        "outputId": "26276575-f8d3-4115-8335-a1564703ac67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250216_215230-1a71405p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nosenkoartyom1989/stickers/runs/1a71405p' target=\"_blank\">helpful-glade-7</a></strong> to <a href='https://wandb.ai/nosenkoartyom1989/stickers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nosenkoartyom1989/stickers' target=\"_blank\">https://wandb.ai/nosenkoartyom1989/stickers</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nosenkoartyom1989/stickers/runs/1a71405p' target=\"_blank\">https://wandb.ai/nosenkoartyom1989/stickers/runs/1a71405p</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.Загружаем данные\n"
      ],
      "metadata": {
        "id": "vXms9UEV5lFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path_to_json = os.path.join(DIR, \"clear_labels.json\")\n",
        "\n",
        "\n",
        "# with open(path_to_json, 'r') as f:\n",
        "#     all_clear_captions = json.load(f)"
      ],
      "metadata": {
        "id": "_QoEReTz8m2c"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompts = pd.read_csv(PATH_PROMPT, index_col=['Unnamed: 0'])\n",
        "# prompts.head()\n",
        "\n",
        "# prompts['prompt'] = prompts['prompt'].apply(lambda x: 'Sticker with unusual dinosaurs' + x[0].lower() + x[1:])"
      ],
      "metadata": {
        "id": "ju8Qw4fA5okM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompts.loc[1, 'prompt']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "5UAjqJqUAFd_",
        "outputId": "042c88d0-026c-481d-e2da-4a9d11dfc41d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sticker with unusual dinosaursthe image features a person wearing a black top hat and a dinosaur mask. The mask is designed to look like a Tyrannosaurus Rex, with a wide-open mouth and sharp teeth. The person is also making a gesture with their hands, which could be interpreted as a celebratory or enthusiastic expression. The background is blurred, but it appears to be a collage of various images, possibly to create a dynamic or artistic effect. The text \"[RUS] !\" suggests that the image is likely meant to be humorous or satirical, possibly referencing a phrase or a theme that is not immediately clear from the image alone.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Запуск экспериментов"
      ],
      "metadata": {
        "id": "17q5n9SSCZ_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  !accelerate launch '/content/drive/MyDrive/dreambooth/train_dreambooth.py' \\\n",
        "#   --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\"  \\\n",
        "#   --instance_data_dir='/content/drive/MyDrive/dino/imgs' \\\n",
        "#   --output_dir='/content/drive/MyDrive/dino/output' \\\n",
        "#   --instance_prompt_path='/content/drive/MyDrive/dino/train.csv' \\\n",
        "#   --num_validation_images=4 \\\n",
        "#   --validation_prompt='Sticker with unusual dinosaursthe wearing a black top hat' \\\n",
        "#   --seed=42 \\\n",
        "#   --resolution=512 \\\n",
        "#   --train_batch_size=4 \\\n",
        "#   --scale_lr \\\n",
        "#   --num_dataloader_workers=4 \\\n",
        "#   --lr_scheduler=\"constant\" \\\n",
        "#   --use_lora \\\n",
        "#   --lora_r=16 \\\n",
        "#   --lora_alpha=32 \\\n",
        "#   --learning_rate=1e-4 \\\n",
        "#   --max_train_steps=800 \\\n",
        "#   --report_to='$wandb_key' \\\n",
        "#   --wandb_key=wandb_token \\\n",
        "#   --wandb_project_name='stickers'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW8xyTVKCZQz",
        "outputId": "8298bfd5-35e5-4ea0-94a8-520503ebda89"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `0`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-16 19:16:03.140362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739733363.173930   49272 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739733363.184137   49272 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-16 19:16:03.221127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: train_dreambooth.py [-h] --pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH\n",
            "                           [--revision REVISION] [--tokenizer_name TOKENIZER_NAME]\n",
            "                           --instance_data_dir INSTANCE_DATA_DIR [--class_data_dir CLASS_DATA_DIR]\n",
            "                           --instance_prompt INSTANCE_PROMPT [--class_prompt CLASS_PROMPT]\n",
            "                           [--with_prior_preservation] [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
            "                           [--num_class_images NUM_CLASS_IMAGES]\n",
            "                           [--validation_prompt VALIDATION_PROMPT]\n",
            "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
            "                           [--validation_steps VALIDATION_STEPS] [--output_dir OUTPUT_DIR]\n",
            "                           [--seed SEED] [--resolution RESOLUTION] [--center_crop]\n",
            "                           [--train_text_encoder] [--use_lora] [--lora_r LORA_R]\n",
            "                           [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n",
            "                           [--lora_bias LORA_BIAS] [--lora_text_encoder_r LORA_TEXT_ENCODER_R]\n",
            "                           [--lora_text_encoder_alpha LORA_TEXT_ENCODER_ALPHA]\n",
            "                           [--lora_text_encoder_dropout LORA_TEXT_ENCODER_DROPOUT]\n",
            "                           [--lora_text_encoder_bias LORA_TEXT_ENCODER_BIAS]\n",
            "                           [--num_dataloader_workers NUM_DATALOADER_WORKERS] [--no_tracemalloc]\n",
            "                           [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                           [--sample_batch_size SAMPLE_BATCH_SIZE]\n",
            "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
            "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
            "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                           [--gradient_checkpointing] [--learning_rate LEARNING_RATE] [--scale_lr]\n",
            "                           [--lr_scheduler LR_SCHEDULER] [--lr_warmup_steps LR_WARMUP_STEPS]\n",
            "                           [--lr_num_cycles LR_NUM_CYCLES] [--lr_power LR_POWER] [--use_8bit_adam]\n",
            "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
            "                           [--adam_weight_decay ADAM_WEIGHT_DECAY] [--adam_epsilon ADAM_EPSILON]\n",
            "                           [--max_grad_norm MAX_GRAD_NORM] [--push_to_hub] [--hub_token HUB_TOKEN]\n",
            "                           [--hub_model_id HUB_MODEL_ID] [--logging_dir LOGGING_DIR]\n",
            "                           [--allow_tf32] [--report_to REPORT_TO] [--wandb_key WANDB_KEY]\n",
            "                           [--wandb_project_name WANDB_PROJECT_NAME]\n",
            "                           [--mixed_precision {no,fp16,bf16}]\n",
            "                           [--prior_generation_precision {no,fp32,fp16,bf16}]\n",
            "                           [--local_rank LOCAL_RANK]\n",
            "                           [--enable_xformers_memory_efficient_attention]\n",
            "train_dreambooth.py: error: the following arguments are required: --instance_prompt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '/content/drive/MyDrive/dreambooth/train_dreambooth.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--instance_data_dir=/content/drive/MyDrive/dino/imgs', '--output_dir=/content/drive/MyDrive/dino/output', '--instance_prompt_path=/content/drive/MyDrive/dino/train.csv', '--num_validation_images=4', '--validation_prompt=Sticker with unusual dinosaursthe wearing a black top hat', '--seed=42', '--resolution=512', '--train_batch_size=4', '--scale_lr', '--num_dataloader_workers=4', '--lr_scheduler=constant', '--use_lora', '--lora_r=16', '--lora_alpha=32', '--learning_rate=1e-4', '--max_train_steps=800', '--report_to=$wandb_key', '--wandb_key=wandb_token', '--wandb_project_name=stickers']' returned non-zero exit status 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch '/content/drive/MyDrive/dreambooth/train_dreambooth.py' \\\n",
        "  --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
        "  --instance_data_dir='/content/drive/MyDrive/dino' \\\n",
        "  --output_dir='/content/drive/MyDrive/dino/output' \\\n",
        "  --train_text_encoder \\\n",
        "  --num_dataloader_workers=1 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=4 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --use_lora \\\n",
        "  --lora_r=16 \\\n",
        "  --lora_alpha=32 \\\n",
        "  --lora_text_encoder_r=16 \\\n",
        "  --lora_text_encoder_alpha=17 \\\n",
        "  --learning_rate=5e-5 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --wandb_key='325ee3ba0ba8c5768ed771e4d9dc8bf9ae9fae6a'\\\n",
        "  --wandb_project_name=\"stickers\" \\\n",
        "  --num_validation_images=10 \\\n",
        "  --validation_prompt=\"Sticker with unusual dinosaursthe wearing a black top hat\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn_uJGO2Oi67",
        "outputId": "14b15c1c-dd56-4b59-8caa-30f1619642b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-16 22:12:59.084640: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-16 22:12:59.103198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739743979.125315   10066 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739743979.132223   10066 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-16 22:12:59.154626: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnosenkoartyom1989\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250216_221303-8teougdb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msage-firebrand-11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nosenkoartyom1989/stickers\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nosenkoartyom1989/stickers/runs/8teougdb\u001b[0m\n",
            "02/16/2025 22:13:04 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'force_upcast', 'latents_mean', 'use_quant_conv', 'mid_block_add_attention', 'use_post_quant_conv', 'shift_factor', 'latents_std', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'mid_block_only_cross_attention', 'addition_time_embed_dim', 'time_cond_proj_dim', 'dual_cross_attention', 'upcast_attention', 'num_attention_heads', 'attention_type', 'class_embed_type', 'only_cross_attention', 'time_embedding_dim', 'transformer_layers_per_block', 'dropout', 'conv_in_kernel', 'addition_embed_type', 'resnet_time_scale_shift', 'reverse_transformer_layers_per_block', 'class_embeddings_concat', 'mid_block_type', 'resnet_out_scale_factor', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'use_linear_projection', 'resnet_skip_time_act', 'num_class_embeds', 'timestep_post_act', 'encoder_hid_dim_type', 'conv_out_kernel', 'time_embedding_type', 'cross_attention_norm', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim'} was not found in config. Values will be initialized to default values.\n",
            "trainable params: 1,594,368 || all params: 861,115,332 || trainable%: 0.1852\n",
            "PeftModel(\n",
            "  (base_model): LoraModel(\n",
            "    (model): UNet2DConditionModel(\n",
            "      (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (time_proj): Timesteps()\n",
            "      (time_embedding): TimestepEmbedding(\n",
            "        (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
            "        (act): SiLU()\n",
            "        (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "      )\n",
            "      (down_blocks): ModuleList(\n",
            "        (0): CrossAttnDownBlock2D(\n",
            "          (attentions): ModuleList(\n",
            "            (0-1): 2 x Transformer2DModel(\n",
            "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (transformer_blocks): ModuleList(\n",
            "                (0): BasicTransformerBlock(\n",
            "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn1): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=320, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=320, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn2): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=320, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=768, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                  (ff): FeedForward(\n",
            "                    (net): ModuleList(\n",
            "                      (0): GEGLU(\n",
            "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                      )\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (resnets): ModuleList(\n",
            "            (0-1): 2 x ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
            "              (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "            )\n",
            "          )\n",
            "          (downsamplers): ModuleList(\n",
            "            (0): Downsample2D(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): CrossAttnDownBlock2D(\n",
            "          (attentions): ModuleList(\n",
            "            (0-1): 2 x Transformer2DModel(\n",
            "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (transformer_blocks): ModuleList(\n",
            "                (0): BasicTransformerBlock(\n",
            "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn1): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=640, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=640, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn2): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=640, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=768, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                  (ff): FeedForward(\n",
            "                    (net): ModuleList(\n",
            "                      (0): GEGLU(\n",
            "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                      )\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (resnets): ModuleList(\n",
            "            (0): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "            )\n",
            "          )\n",
            "          (downsamplers): ModuleList(\n",
            "            (0): Downsample2D(\n",
            "              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): CrossAttnDownBlock2D(\n",
            "          (attentions): ModuleList(\n",
            "            (0-1): 2 x Transformer2DModel(\n",
            "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (transformer_blocks): ModuleList(\n",
            "                (0): BasicTransformerBlock(\n",
            "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn1): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn2): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  (ff): FeedForward(\n",
            "                    (net): ModuleList(\n",
            "                      (0): GEGLU(\n",
            "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                      )\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (resnets): ModuleList(\n",
            "            (0): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "            )\n",
            "          )\n",
            "          (downsamplers): ModuleList(\n",
            "            (0): Downsample2D(\n",
            "              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): DownBlock2D(\n",
            "          (resnets): ModuleList(\n",
            "            (0-1): 2 x ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (up_blocks): ModuleList(\n",
            "        (0): UpBlock2D(\n",
            "          (resnets): ModuleList(\n",
            "            (0-2): 3 x ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (upsamplers): ModuleList(\n",
            "            (0): Upsample2D(\n",
            "              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): CrossAttnUpBlock2D(\n",
            "          (attentions): ModuleList(\n",
            "            (0-2): 3 x Transformer2DModel(\n",
            "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (transformer_blocks): ModuleList(\n",
            "                (0): BasicTransformerBlock(\n",
            "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn1): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn2): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  (ff): FeedForward(\n",
            "                    (net): ModuleList(\n",
            "                      (0): GEGLU(\n",
            "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                      )\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (resnets): ModuleList(\n",
            "            (0-1): 2 x ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (2): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (upsamplers): ModuleList(\n",
            "            (0): Upsample2D(\n",
            "              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): CrossAttnUpBlock2D(\n",
            "          (attentions): ModuleList(\n",
            "            (0-2): 3 x Transformer2DModel(\n",
            "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (transformer_blocks): ModuleList(\n",
            "                (0): BasicTransformerBlock(\n",
            "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn1): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=640, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=640, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn2): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=640, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=768, out_features=640, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=640, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                  (ff): FeedForward(\n",
            "                    (net): ModuleList(\n",
            "                      (0): GEGLU(\n",
            "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                      )\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (resnets): ModuleList(\n",
            "            (0): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (2): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (upsamplers): ModuleList(\n",
            "            (0): Upsample2D(\n",
            "              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): CrossAttnUpBlock2D(\n",
            "          (attentions): ModuleList(\n",
            "            (0-2): 3 x Transformer2DModel(\n",
            "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (transformer_blocks): ModuleList(\n",
            "                (0): BasicTransformerBlock(\n",
            "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn1): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=320, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=320, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                  (attn2): Attention(\n",
            "                    (to_q): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=320, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                    (to_v): lora.Linear(\n",
            "                      (base_layer): Linear(in_features=768, out_features=320, bias=False)\n",
            "                      (lora_dropout): ModuleDict(\n",
            "                        (default): Identity()\n",
            "                      )\n",
            "                      (lora_A): ModuleDict(\n",
            "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                      )\n",
            "                      (lora_B): ModuleDict(\n",
            "                        (default): Linear(in_features=16, out_features=320, bias=False)\n",
            "                      )\n",
            "                      (lora_embedding_A): ParameterDict()\n",
            "                      (lora_embedding_B): ParameterDict()\n",
            "                      (lora_magnitude_vector): ModuleDict()\n",
            "                    )\n",
            "                    (to_out): ModuleList(\n",
            "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                  (ff): FeedForward(\n",
            "                    (net): ModuleList(\n",
            "                      (0): GEGLU(\n",
            "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                      )\n",
            "                      (1): Dropout(p=0.0, inplace=False)\n",
            "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (resnets): ModuleList(\n",
            "            (0): ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
            "              (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1-2): 2 x ResnetBlock2D(\n",
            "              (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "              (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
            "              (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nonlinearity): SiLU()\n",
            "              (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (mid_block): UNetMidBlock2DCrossAttn(\n",
            "        (attentions): ModuleList(\n",
            "          (0): Transformer2DModel(\n",
            "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (attn1): Attention(\n",
            "                  (to_q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Identity()\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Identity()\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (to_out): ModuleList(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (attn2): Attention(\n",
            "                  (to_q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Identity()\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Identity()\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (to_out): ModuleList(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (ff): FeedForward(\n",
            "                  (net): ModuleList(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (resnets): ModuleList(\n",
            "          (0-1): 2 x ResnetBlock2D(\n",
            "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "            (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (nonlinearity): SiLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "      (conv_act): SiLU()\n",
            "      (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "trainable params: 589,824 || all params: 123,650,304 || trainable%: 0.4770\n",
            "PeftModel(\n",
            "  (base_model): LoraModel(\n",
            "    (model): CLIPTextModel(\n",
            "      (text_model): CLIPTextTransformer(\n",
            "        (embeddings): CLIPTextEmbeddings(\n",
            "          (token_embedding): Embedding(49408, 768)\n",
            "          (position_embedding): Embedding(77, 768)\n",
            "        )\n",
            "        (encoder): CLIPEncoder(\n",
            "          (layers): ModuleList(\n",
            "            (0-11): 12 x CLIPEncoderLayer(\n",
            "              (self_attn): CLIPSdpaAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Identity()\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (q_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Identity()\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "02/16/2025 22:13:08 - INFO - __main__ - ***** Running training *****\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Num examples = 84\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Num batches each epoch = 21\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Num Epochs = 96\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/16/2025 22:13:08 - INFO - __main__ -   Total optimization steps = 2000\n",
            "Steps:   0% 0/2000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "Steps:   0% 1/2000 [00:10<5:55:14, 10.66s/it]Steps:   0% 1/2000 [00:10<5:55:14, 10.66s/it]\n",
            "Steps:   0% 1/2000 [00:10<5:55:14, 10.66s/it, loss=0.127, lr=5e-5]02/16/2025 22:13:19 - INFO - __main__ - Running validation... \n",
            " Generating 10 images with prompt: Sticker with unusual dinosaursthe wearing a black top hat.\n",
            "\n",
            "model_index.json: 100% 541/541 [00:00<00:00, 1.62MB/s]\n",
            "\n",
            "Fetching 14 files:   0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "(…)ure_extractor%2Fpreprocessor_config.json: 100% 342/342 [00:00<00:00, 1.30MB/s]\n",
            "\n",
            "Fetching 14 files:   7% 1/14 [00:00<00:06,  2.07it/s]\u001b[A\n",
            "\n",
            "(…)oints%2Fscheduler_config-checkpoint.json: 100% 209/209 [00:00<00:00, 1.14MB/s]\n",
            "\n",
            "\n",
            "scheduler%2Fscheduler_config.json: 100% 313/313 [00:00<00:00, 1.19MB/s]\n",
            "Fetching 14 files: 100% 14/14 [00:00<00:00, 26.55it/s]\n",
            "{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  17% 1/6 [00:00<00:02,  1.76it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'force_upcast', 'latents_mean', 'use_quant_conv', 'mid_block_add_attention', 'use_post_quant_conv', 'shift_factor', 'latents_std', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  50% 3/6 [00:00<00:00,  5.39it/s]\u001b[A{'mid_block_only_cross_attention', 'addition_time_embed_dim', 'time_cond_proj_dim', 'dual_cross_attention', 'upcast_attention', 'num_attention_heads', 'attention_type', 'class_embed_type', 'only_cross_attention', 'time_embedding_dim', 'transformer_layers_per_block', 'dropout', 'conv_in_kernel', 'addition_embed_type', 'resnet_time_scale_shift', 'reverse_transformer_layers_per_block', 'class_embeddings_concat', 'mid_block_type', 'resnet_out_scale_factor', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'use_linear_projection', 'resnet_skip_time_act', 'num_class_embeds', 'timestep_post_act', 'encoder_hid_dim_type', 'conv_out_kernel', 'time_embedding_type', 'cross_attention_norm', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:01<00:00,  5.44it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 6/6 [00:01<00:00,  5.59it/s]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'use_exponential_sigmas', 'sample_max_value', 'solver_type', 'thresholding', 'lambda_min_clipped', 'solver_order', 'use_flow_sigmas', 'final_sigmas_type', 'prediction_type', 'dynamic_thresholding_ratio', 'use_karras_sigmas', 'euler_at_final', 'use_beta_sigmas', 'algorithm_type', 'use_lu_lambdas', 'rescale_betas_zero_snr', 'timestep_spacing', 'variance_type', 'flow_shift', 'lower_order_final'} was not found in config. Values will be initialized to default values.\n",
            "Steps:   0% 2/2000 [00:43<13:11:13, 23.76s/it, loss=0.127, lr=5e-5]Steps:   0% 2/2000 [00:43<13:11:13, 23.76s/it, loss=0.127, lr=5e-5]\n",
            "Steps:   0% 3/2000 [00:44<7:20:12, 13.23s/it, loss=0.0789, lr=5e-5] Steps:   0% 3/2000 [00:44<7:20:12, 13.23s/it, loss=0.0789, lr=5e-5]\n",
            "Steps:   0% 4/2000 [00:48<5:18:06,  9.56s/it, loss=0.0768, lr=5e-5]Steps:   0% 4/2000 [00:48<5:18:06,  9.56s/it, loss=0.0768, lr=5e-5]\n",
            "Steps:   0% 5/2000 [00:52<4:18:27,  7.77s/it, loss=0.00939, lr=5e-5]Steps:   0% 5/2000 [00:52<4:18:27,  7.77s/it, loss=0.00939, lr=5e-5]\n",
            "Steps:   0% 6/2000 [00:57<3:45:12,  6.78s/it, loss=0.0716, lr=5e-5]Steps:   0% 6/2000 [00:57<3:45:12,  6.78s/it, loss=0.0716, lr=5e-5]\n",
            "Steps:   0% 7/2000 [01:02<3:22:29,  6.10s/it, loss=0.142, lr=5e-5]Steps:   0% 7/2000 [01:02<3:22:29,  6.10s/it, loss=0.142, lr=5e-5]\n",
            "Steps:   0% 8/2000 [01:06<2:56:52,  5.33s/it, loss=0.0664, lr=5e-5]Steps:   0% 8/2000 [01:06<2:56:52,  5.33s/it, loss=0.0664, lr=5e-5]\n",
            "Steps:   0% 9/2000 [01:10<2:46:43,  5.02s/it, loss=0.0896, lr=5e-5]Steps:   0% 9/2000 [01:10<2:46:43,  5.02s/it, loss=0.0896, lr=5e-5]\n",
            "Steps:   0% 10/2000 [01:14<2:39:03,  4.80s/it, loss=0.0877, lr=5e-5]Steps:   0% 10/2000 [01:14<2:39:03,  4.80s/it, loss=0.0877, lr=5e-5]\n",
            "Steps:   1% 11/2000 [01:18<2:30:38,  4.54s/it, loss=0.0457, lr=5e-5]Steps:   1% 11/2000 [01:18<2:30:38,  4.54s/it, loss=0.0457, lr=5e-5]\n",
            "Steps:   1% 12/2000 [01:23<2:33:59,  4.65s/it, loss=0.0599, lr=5e-5]Steps:   1% 12/2000 [01:23<2:33:59,  4.65s/it, loss=0.0599, lr=5e-5]\n",
            "Steps:   1% 13/2000 [01:27<2:26:35,  4.43s/it, loss=0.095, lr=5e-5]Steps:   1% 13/2000 [01:27<2:26:35,  4.43s/it, loss=0.095, lr=5e-5]\n",
            "Steps:   1% 14/2000 [01:30<2:17:13,  4.15s/it, loss=0.151, lr=5e-5]Steps:   1% 14/2000 [01:30<2:17:13,  4.15s/it, loss=0.151, lr=5e-5]\n",
            "Steps:   1% 15/2000 [01:36<2:27:48,  4.47s/it, loss=0.0791, lr=5e-5]Steps:   1% 15/2000 [01:36<2:27:48,  4.47s/it, loss=0.0791, lr=5e-5]\n",
            "Steps:   1% 16/2000 [01:40<2:24:29,  4.37s/it, loss=0.133, lr=5e-5]Steps:   1% 16/2000 [01:40<2:24:29,  4.37s/it, loss=0.133, lr=5e-5]\n",
            "Steps:   1% 17/2000 [01:45<2:27:38,  4.47s/it, loss=0.106, lr=5e-5]Steps:   1% 17/2000 [01:45<2:27:38,  4.47s/it, loss=0.106, lr=5e-5]\n",
            "Steps:   1% 18/2000 [01:48<2:16:30,  4.13s/it, loss=0.141, lr=5e-5]Steps:   1% 18/2000 [01:48<2:16:30,  4.13s/it, loss=0.141, lr=5e-5]\n",
            "Steps:   1% 19/2000 [01:52<2:21:03,  4.27s/it, loss=0.0682, lr=5e-5]Steps:   1% 19/2000 [01:52<2:21:03,  4.27s/it, loss=0.0682, lr=5e-5]\n",
            "Steps:   1% 20/2000 [01:57<2:22:01,  4.30s/it, loss=0.0546, lr=5e-5]Steps:   1% 20/2000 [01:57<2:22:01,  4.30s/it, loss=0.0546, lr=5e-5]\n",
            "Steps:   1% 21/2000 [01:58<1:46:22,  3.23s/it, loss=0.0901, lr=5e-5]Steps:   1% 21/2000 [01:58<1:46:22,  3.23s/it, loss=0.0901, lr=5e-5]\n",
            "Steps:   1% 21/2000 [01:58<1:46:22,  3.23s/it, loss=0.103, lr=5e-5] GPU Memory before entering the train : 3936\n",
            "GPU Memory consumed at the end of the train (end-begin): 46\n",
            "GPU Peak Memory consumed during the train (max-begin): 1588\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 1524\n",
            "CPU Memory consumed at the end of the train (end-begin): 1098\n",
            "CPU Peak Memory consumed during the train (max-begin): 1218\n",
            "CPU Total Peak Memory consumed during the train (max): 2742\n",
            "Steps:   1% 22/2000 [01:59<1:30:18,  2.74s/it, loss=0.103, lr=5e-5]Steps:   1% 22/2000 [01:59<1:30:18,  2.74s/it, loss=0.103, lr=5e-5]\n",
            "Steps:   1% 23/2000 [02:00<1:09:56,  2.12s/it, loss=0.0584, lr=5e-5]Steps:   1% 23/2000 [02:00<1:09:56,  2.12s/it, loss=0.0584, lr=5e-5]\n",
            "Steps:   1% 24/2000 [02:01<55:40,  1.69s/it, loss=0.137, lr=5e-5]  Steps:   1% 24/2000 [02:01<55:40,  1.69s/it, loss=0.137, lr=5e-5]\n",
            "Steps:   1% 25/2000 [02:01<45:41,  1.39s/it, loss=0.0441, lr=5e-5]Steps:   1% 25/2000 [02:01<45:41,  1.39s/it, loss=0.0441, lr=5e-5]\n",
            "Steps:   1% 26/2000 [02:02<38:41,  1.18s/it, loss=0.13, lr=5e-5]Steps:   1% 26/2000 [02:02<38:41,  1.18s/it, loss=0.13, lr=5e-5]\n",
            "Steps:   1% 27/2000 [02:03<33:48,  1.03s/it, loss=0.262, lr=5e-5]Steps:   1% 27/2000 [02:03<33:48,  1.03s/it, loss=0.262, lr=5e-5]\n",
            "Steps:   1% 28/2000 [02:03<30:25,  1.08it/s, loss=0.148, lr=5e-5]Steps:   1% 28/2000 [02:03<30:25,  1.08it/s, loss=0.148, lr=5e-5]\n",
            "Steps:   1% 29/2000 [02:04<28:01,  1.17it/s, loss=0.105, lr=5e-5]Steps:   1% 29/2000 [02:04<28:01,  1.17it/s, loss=0.105, lr=5e-5]\n",
            "Steps:   2% 30/2000 [02:05<26:18,  1.25it/s, loss=0.251, lr=5e-5]Steps:   2% 30/2000 [02:05<26:18,  1.25it/s, loss=0.251, lr=5e-5]\n",
            "Steps:   2% 31/2000 [02:05<25:08,  1.30it/s, loss=0.0623, lr=5e-5]Steps:   2% 31/2000 [02:05<25:08,  1.30it/s, loss=0.0623, lr=5e-5]\n",
            "Steps:   2% 32/2000 [02:06<24:19,  1.35it/s, loss=0.0575, lr=5e-5]Steps:   2% 32/2000 [02:06<24:19,  1.35it/s, loss=0.0575, lr=5e-5]\n",
            "Steps:   2% 33/2000 [02:07<23:51,  1.37it/s, loss=0.0547, lr=5e-5]Steps:   2% 33/2000 [02:07<23:51,  1.37it/s, loss=0.0547, lr=5e-5]\n",
            "Steps:   2% 34/2000 [02:07<23:29,  1.40it/s, loss=0.0449, lr=5e-5]Steps:   2% 34/2000 [02:07<23:29,  1.40it/s, loss=0.0449, lr=5e-5]\n",
            "Steps:   2% 35/2000 [02:08<23:24,  1.40it/s, loss=0.0555, lr=5e-5]Steps:   2% 35/2000 [02:08<23:24,  1.40it/s, loss=0.0555, lr=5e-5]\n",
            "Steps:   2% 36/2000 [02:09<23:05,  1.42it/s, loss=0.11, lr=5e-5]Steps:   2% 36/2000 [02:09<23:05,  1.42it/s, loss=0.11, lr=5e-5]\n",
            "Steps:   2% 37/2000 [02:09<22:53,  1.43it/s, loss=0.04, lr=5e-5]Steps:   2% 37/2000 [02:09<22:53,  1.43it/s, loss=0.04, lr=5e-5]\n",
            "Steps:   2% 38/2000 [02:10<22:44,  1.44it/s, loss=0.0322, lr=5e-5]Steps:   2% 38/2000 [02:10<22:44,  1.44it/s, loss=0.0322, lr=5e-5]\n",
            "Steps:   2% 39/2000 [02:11<22:36,  1.45it/s, loss=0.129, lr=5e-5]Steps:   2% 39/2000 [02:11<22:36,  1.45it/s, loss=0.129, lr=5e-5]\n",
            "Steps:   2% 40/2000 [02:12<22:35,  1.45it/s, loss=0.241, lr=5e-5]Steps:   2% 40/2000 [02:12<22:35,  1.45it/s, loss=0.241, lr=5e-5]\n",
            "Steps:   2% 41/2000 [02:12<22:29,  1.45it/s, loss=0.0376, lr=5e-5]Steps:   2% 41/2000 [02:12<22:29,  1.45it/s, loss=0.0376, lr=5e-5]\n",
            "Steps:   2% 42/2000 [02:13<22:39,  1.44it/s, loss=0.234, lr=5e-5]Steps:   2% 42/2000 [02:13<22:39,  1.44it/s, loss=0.234, lr=5e-5]\n",
            "Steps:   2% 42/2000 [02:13<22:39,  1.44it/s, loss=0.0902, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2623\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2635\n",
            "Steps:   2% 43/2000 [02:15<31:54,  1.02it/s, loss=0.0902, lr=5e-5]Steps:   2% 43/2000 [02:15<31:54,  1.02it/s, loss=0.0902, lr=5e-5]\n",
            "Steps:   2% 44/2000 [02:15<29:05,  1.12it/s, loss=0.0409, lr=5e-5]Steps:   2% 44/2000 [02:15<29:05,  1.12it/s, loss=0.0409, lr=5e-5]\n",
            "Steps:   2% 45/2000 [02:16<27:05,  1.20it/s, loss=0.118, lr=5e-5]Steps:   2% 45/2000 [02:16<27:05,  1.20it/s, loss=0.118, lr=5e-5]\n",
            "Steps:   2% 46/2000 [02:17<25:41,  1.27it/s, loss=0.0621, lr=5e-5]Steps:   2% 46/2000 [02:17<25:41,  1.27it/s, loss=0.0621, lr=5e-5]\n",
            "Steps:   2% 47/2000 [02:17<24:43,  1.32it/s, loss=0.0656, lr=5e-5]Steps:   2% 47/2000 [02:17<24:43,  1.32it/s, loss=0.0656, lr=5e-5]\n",
            "Steps:   2% 48/2000 [02:18<24:01,  1.35it/s, loss=0.0662, lr=5e-5]Steps:   2% 48/2000 [02:18<24:01,  1.35it/s, loss=0.0662, lr=5e-5]\n",
            "Steps:   2% 49/2000 [02:19<23:33,  1.38it/s, loss=0.116, lr=5e-5]Steps:   2% 49/2000 [02:19<23:33,  1.38it/s, loss=0.116, lr=5e-5]\n",
            "Steps:   2% 50/2000 [02:19<23:11,  1.40it/s, loss=0.0921, lr=5e-5]Steps:   2% 50/2000 [02:19<23:11,  1.40it/s, loss=0.0921, lr=5e-5]\n",
            "Steps:   3% 51/2000 [02:20<22:56,  1.42it/s, loss=0.036, lr=5e-5]Steps:   3% 51/2000 [02:20<22:56,  1.42it/s, loss=0.036, lr=5e-5]\n",
            "Steps:   3% 52/2000 [02:21<22:51,  1.42it/s, loss=0.139, lr=5e-5]Steps:   3% 52/2000 [02:21<22:51,  1.42it/s, loss=0.139, lr=5e-5]\n",
            "Steps:   3% 53/2000 [02:21<22:44,  1.43it/s, loss=0.0463, lr=5e-5]Steps:   3% 53/2000 [02:21<22:44,  1.43it/s, loss=0.0463, lr=5e-5]\n",
            "Steps:   3% 54/2000 [02:22<22:36,  1.43it/s, loss=0.0887, lr=5e-5]Steps:   3% 54/2000 [02:22<22:36,  1.43it/s, loss=0.0887, lr=5e-5]\n",
            "Steps:   3% 55/2000 [02:23<22:34,  1.44it/s, loss=0.0385, lr=5e-5]Steps:   3% 55/2000 [02:23<22:34,  1.44it/s, loss=0.0385, lr=5e-5]\n",
            "Steps:   3% 56/2000 [02:24<22:30,  1.44it/s, loss=0.0418, lr=5e-5]Steps:   3% 56/2000 [02:24<22:30,  1.44it/s, loss=0.0418, lr=5e-5]\n",
            "Steps:   3% 57/2000 [02:24<22:27,  1.44it/s, loss=0.0981, lr=5e-5]Steps:   3% 57/2000 [02:24<22:27,  1.44it/s, loss=0.0981, lr=5e-5]\n",
            "Steps:   3% 58/2000 [02:25<22:28,  1.44it/s, loss=0.117, lr=5e-5]Steps:   3% 58/2000 [02:25<22:28,  1.44it/s, loss=0.117, lr=5e-5]\n",
            "Steps:   3% 59/2000 [02:26<22:28,  1.44it/s, loss=0.215, lr=5e-5]Steps:   3% 59/2000 [02:26<22:28,  1.44it/s, loss=0.215, lr=5e-5]\n",
            "Steps:   3% 60/2000 [02:26<22:24,  1.44it/s, loss=0.141, lr=5e-5]Steps:   3% 60/2000 [02:26<22:24,  1.44it/s, loss=0.141, lr=5e-5]\n",
            "Steps:   3% 61/2000 [02:27<22:24,  1.44it/s, loss=0.0621, lr=5e-5]Steps:   3% 61/2000 [02:27<22:24,  1.44it/s, loss=0.0621, lr=5e-5]\n",
            "Steps:   3% 62/2000 [02:28<22:23,  1.44it/s, loss=0.135, lr=5e-5]Steps:   3% 62/2000 [02:28<22:23,  1.44it/s, loss=0.135, lr=5e-5]\n",
            "Steps:   3% 63/2000 [02:28<22:38,  1.43it/s, loss=0.0569, lr=5e-5]Steps:   3% 63/2000 [02:28<22:38,  1.43it/s, loss=0.0569, lr=5e-5]\n",
            "Steps:   3% 63/2000 [02:28<22:38,  1.43it/s, loss=0.134, lr=5e-5] GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2623\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2635\n",
            "Steps:   3% 64/2000 [02:30<31:46,  1.02it/s, loss=0.134, lr=5e-5]Steps:   3% 64/2000 [02:30<31:46,  1.02it/s, loss=0.134, lr=5e-5]\n",
            "Steps:   3% 65/2000 [02:31<29:23,  1.10it/s, loss=0.0739, lr=5e-5]Steps:   3% 65/2000 [02:31<29:23,  1.10it/s, loss=0.0739, lr=5e-5]\n",
            "Steps:   3% 66/2000 [02:31<27:15,  1.18it/s, loss=0.0417, lr=5e-5]Steps:   3% 66/2000 [02:31<27:15,  1.18it/s, loss=0.0417, lr=5e-5]\n",
            "Steps:   3% 67/2000 [02:32<25:46,  1.25it/s, loss=0.0384, lr=5e-5]Steps:   3% 67/2000 [02:32<25:46,  1.25it/s, loss=0.0384, lr=5e-5]\n",
            "Steps:   3% 68/2000 [02:33<24:44,  1.30it/s, loss=0.162, lr=5e-5]Steps:   3% 68/2000 [02:33<24:44,  1.30it/s, loss=0.162, lr=5e-5]\n",
            "Steps:   3% 69/2000 [02:34<23:59,  1.34it/s, loss=0.0837, lr=5e-5]Steps:   3% 69/2000 [02:34<23:59,  1.34it/s, loss=0.0837, lr=5e-5]\n",
            "Steps:   4% 70/2000 [02:34<23:27,  1.37it/s, loss=0.102, lr=5e-5]Steps:   4% 70/2000 [02:34<23:27,  1.37it/s, loss=0.102, lr=5e-5]\n",
            "Steps:   4% 71/2000 [02:35<23:04,  1.39it/s, loss=0.0675, lr=5e-5]Steps:   4% 71/2000 [02:35<23:04,  1.39it/s, loss=0.0675, lr=5e-5]\n",
            "Steps:   4% 72/2000 [02:36<22:49,  1.41it/s, loss=0.0291, lr=5e-5]Steps:   4% 72/2000 [02:36<22:49,  1.41it/s, loss=0.0291, lr=5e-5]\n",
            "Steps:   4% 73/2000 [02:36<22:37,  1.42it/s, loss=0.194, lr=5e-5]Steps:   4% 73/2000 [02:36<22:37,  1.42it/s, loss=0.194, lr=5e-5]\n",
            "Steps:   4% 74/2000 [02:37<22:51,  1.40it/s, loss=0.0782, lr=5e-5]Steps:   4% 74/2000 [02:37<22:51,  1.40it/s, loss=0.0782, lr=5e-5]\n",
            "Steps:   4% 75/2000 [02:38<22:37,  1.42it/s, loss=0.0491, lr=5e-5]Steps:   4% 75/2000 [02:38<22:37,  1.42it/s, loss=0.0491, lr=5e-5]\n",
            "Steps:   4% 76/2000 [02:38<22:31,  1.42it/s, loss=0.165, lr=5e-5]Steps:   4% 76/2000 [02:38<22:31,  1.42it/s, loss=0.165, lr=5e-5]\n",
            "Steps:   4% 77/2000 [02:39<22:25,  1.43it/s, loss=0.153, lr=5e-5]Steps:   4% 77/2000 [02:39<22:25,  1.43it/s, loss=0.153, lr=5e-5]\n",
            "Steps:   4% 78/2000 [02:40<22:21,  1.43it/s, loss=0.0687, lr=5e-5]Steps:   4% 78/2000 [02:40<22:21,  1.43it/s, loss=0.0687, lr=5e-5]\n",
            "Steps:   4% 79/2000 [02:41<22:20,  1.43it/s, loss=0.144, lr=5e-5]Steps:   4% 79/2000 [02:41<22:20,  1.43it/s, loss=0.144, lr=5e-5]\n",
            "Steps:   4% 80/2000 [02:41<22:20,  1.43it/s, loss=0.0546, lr=5e-5]Steps:   4% 80/2000 [02:41<22:20,  1.43it/s, loss=0.0546, lr=5e-5]\n",
            "Steps:   4% 81/2000 [02:42<22:20,  1.43it/s, loss=0.0731, lr=5e-5]Steps:   4% 81/2000 [02:42<22:20,  1.43it/s, loss=0.0731, lr=5e-5]\n",
            "Steps:   4% 82/2000 [02:43<22:21,  1.43it/s, loss=0.14, lr=5e-5]Steps:   4% 82/2000 [02:43<22:21,  1.43it/s, loss=0.14, lr=5e-5]\n",
            "Steps:   4% 83/2000 [02:43<22:47,  1.40it/s, loss=0.0803, lr=5e-5]Steps:   4% 83/2000 [02:43<22:47,  1.40it/s, loss=0.0803, lr=5e-5]\n",
            "Steps:   4% 84/2000 [02:44<22:57,  1.39it/s, loss=0.167, lr=5e-5]Steps:   4% 84/2000 [02:44<22:57,  1.39it/s, loss=0.167, lr=5e-5]\n",
            "Steps:   4% 84/2000 [02:44<22:57,  1.39it/s, loss=0.0299, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2623\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2635\n",
            "Steps:   4% 85/2000 [02:46<32:24,  1.02s/it, loss=0.0299, lr=5e-5]Steps:   4% 85/2000 [02:46<32:24,  1.02s/it, loss=0.0299, lr=5e-5]\n",
            "Steps:   4% 86/2000 [02:47<29:23,  1.09it/s, loss=0.0158, lr=5e-5]Steps:   4% 86/2000 [02:47<29:23,  1.09it/s, loss=0.0158, lr=5e-5]\n",
            "Steps:   4% 87/2000 [02:47<27:14,  1.17it/s, loss=0.0637, lr=5e-5]Steps:   4% 87/2000 [02:47<27:14,  1.17it/s, loss=0.0637, lr=5e-5]\n",
            "Steps:   4% 88/2000 [02:48<25:43,  1.24it/s, loss=0.293, lr=5e-5]Steps:   4% 88/2000 [02:48<25:43,  1.24it/s, loss=0.293, lr=5e-5]\n",
            "Steps:   4% 89/2000 [02:49<24:57,  1.28it/s, loss=0.129, lr=5e-5]Steps:   4% 89/2000 [02:49<24:57,  1.28it/s, loss=0.129, lr=5e-5]\n",
            "Steps:   4% 90/2000 [02:49<24:06,  1.32it/s, loss=0.0985, lr=5e-5]Steps:   4% 90/2000 [02:49<24:06,  1.32it/s, loss=0.0985, lr=5e-5]\n",
            "Steps:   5% 91/2000 [02:50<23:29,  1.35it/s, loss=0.0569, lr=5e-5]Steps:   5% 91/2000 [02:50<23:29,  1.35it/s, loss=0.0569, lr=5e-5]\n",
            "Steps:   5% 92/2000 [02:51<23:06,  1.38it/s, loss=0.0693, lr=5e-5]Steps:   5% 92/2000 [02:51<23:06,  1.38it/s, loss=0.0693, lr=5e-5]\n",
            "Steps:   5% 93/2000 [02:51<22:48,  1.39it/s, loss=0.0941, lr=5e-5]Steps:   5% 93/2000 [02:51<22:48,  1.39it/s, loss=0.0941, lr=5e-5]\n",
            "Steps:   5% 94/2000 [02:52<22:37,  1.40it/s, loss=0.0741, lr=5e-5]Steps:   5% 94/2000 [02:52<22:37,  1.40it/s, loss=0.0741, lr=5e-5]\n",
            "Steps:   5% 95/2000 [02:53<22:29,  1.41it/s, loss=0.121, lr=5e-5]Steps:   5% 95/2000 [02:53<22:29,  1.41it/s, loss=0.121, lr=5e-5]\n",
            "Steps:   5% 96/2000 [02:54<22:38,  1.40it/s, loss=0.0981, lr=5e-5]Steps:   5% 96/2000 [02:54<22:38,  1.40it/s, loss=0.0981, lr=5e-5]\n",
            "Steps:   5% 97/2000 [02:54<22:23,  1.42it/s, loss=0.0977, lr=5e-5]Steps:   5% 97/2000 [02:54<22:23,  1.42it/s, loss=0.0977, lr=5e-5]\n",
            "Steps:   5% 98/2000 [02:55<22:48,  1.39it/s, loss=0.0104, lr=5e-5]Steps:   5% 98/2000 [02:55<22:48,  1.39it/s, loss=0.0104, lr=5e-5]\n",
            "Steps:   5% 99/2000 [02:56<22:36,  1.40it/s, loss=0.125, lr=5e-5]Steps:   5% 99/2000 [02:56<22:36,  1.40it/s, loss=0.125, lr=5e-5]\n",
            "Steps:   5% 100/2000 [02:56<22:24,  1.41it/s, loss=0.185, lr=5e-5]Steps:   5% 100/2000 [02:56<22:24,  1.41it/s, loss=0.185, lr=5e-5]\n",
            "Steps:   5% 101/2000 [02:57<22:19,  1.42it/s, loss=0.217, lr=5e-5]Steps:   5% 101/2000 [02:57<22:19,  1.42it/s, loss=0.217, lr=5e-5]\n",
            "Steps:   5% 101/2000 [02:57<22:19,  1.42it/s, loss=0.107, lr=5e-5]02/16/2025 22:16:06 - INFO - __main__ - Running validation... \n",
            " Generating 10 images with prompt: Sticker with unusual dinosaursthe wearing a black top hat.\n",
            "{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  17% 1/6 [00:00<00:02,  1.74it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'force_upcast', 'latents_mean', 'use_quant_conv', 'mid_block_add_attention', 'use_post_quant_conv', 'shift_factor', 'latents_std', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  50% 3/6 [00:00<00:00,  5.29it/s]\u001b[A{'mid_block_only_cross_attention', 'addition_time_embed_dim', 'time_cond_proj_dim', 'dual_cross_attention', 'upcast_attention', 'num_attention_heads', 'attention_type', 'class_embed_type', 'only_cross_attention', 'time_embedding_dim', 'transformer_layers_per_block', 'dropout', 'conv_in_kernel', 'addition_embed_type', 'resnet_time_scale_shift', 'reverse_transformer_layers_per_block', 'class_embeddings_concat', 'mid_block_type', 'resnet_out_scale_factor', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'use_linear_projection', 'resnet_skip_time_act', 'num_class_embeds', 'timestep_post_act', 'encoder_hid_dim_type', 'conv_out_kernel', 'time_embedding_type', 'cross_attention_norm', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:01<00:00,  5.05it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 6/6 [00:01<00:00,  5.46it/s]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'use_exponential_sigmas', 'sample_max_value', 'solver_type', 'thresholding', 'lambda_min_clipped', 'solver_order', 'use_flow_sigmas', 'final_sigmas_type', 'prediction_type', 'dynamic_thresholding_ratio', 'use_karras_sigmas', 'euler_at_final', 'use_beta_sigmas', 'algorithm_type', 'use_lu_lambdas', 'rescale_betas_zero_snr', 'timestep_spacing', 'variance_type', 'flow_shift', 'lower_order_final'} was not found in config. Values will be initialized to default values.\n",
            "Steps:   5% 102/2000 [03:29<5:14:09,  9.93s/it, loss=0.107, lr=5e-5]Steps:   5% 102/2000 [03:29<5:14:09,  9.93s/it, loss=0.107, lr=5e-5]\n",
            "Steps:   5% 103/2000 [03:29<3:46:19,  7.16s/it, loss=0.119, lr=5e-5]Steps:   5% 103/2000 [03:29<3:46:19,  7.16s/it, loss=0.119, lr=5e-5]\n",
            "Steps:   5% 104/2000 [03:30<2:44:54,  5.22s/it, loss=0.0428, lr=5e-5]Steps:   5% 104/2000 [03:30<2:44:54,  5.22s/it, loss=0.0428, lr=5e-5]\n",
            "Steps:   5% 105/2000 [03:31<2:02:13,  3.87s/it, loss=0.154, lr=5e-5]Steps:   5% 105/2000 [03:31<2:02:13,  3.87s/it, loss=0.154, lr=5e-5]\n",
            "Steps:   5% 105/2000 [03:31<2:02:13,  3.87s/it, loss=0.0154, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2623\n",
            "CPU Memory consumed at the end of the train (end-begin): 5\n",
            "CPU Peak Memory consumed during the train (max-begin): 328\n",
            "CPU Total Peak Memory consumed during the train (max): 2951\n",
            "Steps:   5% 106/2000 [03:32<1:40:44,  3.19s/it, loss=0.0154, lr=5e-5]Steps:   5% 106/2000 [03:32<1:40:44,  3.19s/it, loss=0.0154, lr=5e-5]\n",
            "Steps:   5% 107/2000 [03:33<1:17:00,  2.44s/it, loss=0.0762, lr=5e-5]Steps:   5% 107/2000 [03:33<1:17:00,  2.44s/it, loss=0.0762, lr=5e-5]\n",
            "Steps:   5% 108/2000 [03:34<1:00:21,  1.91s/it, loss=0.144, lr=5e-5]Steps:   5% 108/2000 [03:34<1:00:21,  1.91s/it, loss=0.144, lr=5e-5]\n",
            "Steps:   5% 109/2000 [03:34<48:42,  1.55s/it, loss=0.167, lr=5e-5]  Steps:   5% 109/2000 [03:34<48:42,  1.55s/it, loss=0.167, lr=5e-5]\n",
            "Steps:   6% 110/2000 [03:35<40:56,  1.30s/it, loss=0.07, lr=5e-5]Steps:   6% 110/2000 [03:35<40:56,  1.30s/it, loss=0.07, lr=5e-5]\n",
            "Steps:   6% 111/2000 [03:36<35:08,  1.12s/it, loss=0.0536, lr=5e-5]Steps:   6% 111/2000 [03:36<35:08,  1.12s/it, loss=0.0536, lr=5e-5]\n",
            "Steps:   6% 112/2000 [03:36<31:27,  1.00it/s, loss=0.232, lr=5e-5]Steps:   6% 112/2000 [03:36<31:27,  1.00it/s, loss=0.232, lr=5e-5]\n",
            "Steps:   6% 113/2000 [03:37<28:38,  1.10it/s, loss=0.12, lr=5e-5]Steps:   6% 113/2000 [03:37<28:38,  1.10it/s, loss=0.12, lr=5e-5]\n",
            "Steps:   6% 114/2000 [03:38<26:39,  1.18it/s, loss=0.124, lr=5e-5]Steps:   6% 114/2000 [03:38<26:39,  1.18it/s, loss=0.124, lr=5e-5]\n",
            "Steps:   6% 115/2000 [03:39<25:09,  1.25it/s, loss=0.149, lr=5e-5]Steps:   6% 115/2000 [03:39<25:09,  1.25it/s, loss=0.149, lr=5e-5]\n",
            "Steps:   6% 116/2000 [03:39<24:09,  1.30it/s, loss=0.112, lr=5e-5]Steps:   6% 116/2000 [03:39<24:09,  1.30it/s, loss=0.112, lr=5e-5]\n",
            "Steps:   6% 117/2000 [03:40<23:28,  1.34it/s, loss=0.0459, lr=5e-5]Steps:   6% 117/2000 [03:40<23:28,  1.34it/s, loss=0.0459, lr=5e-5]\n",
            "Steps:   6% 118/2000 [03:41<22:56,  1.37it/s, loss=0.0721, lr=5e-5]Steps:   6% 118/2000 [03:41<22:56,  1.37it/s, loss=0.0721, lr=5e-5]\n",
            "Steps:   6% 119/2000 [03:41<22:29,  1.39it/s, loss=0.121, lr=5e-5]Steps:   6% 119/2000 [03:41<22:29,  1.39it/s, loss=0.121, lr=5e-5]\n",
            "Steps:   6% 120/2000 [03:42<22:17,  1.41it/s, loss=0.0259, lr=5e-5]Steps:   6% 120/2000 [03:42<22:17,  1.41it/s, loss=0.0259, lr=5e-5]\n",
            "Steps:   6% 121/2000 [03:43<22:03,  1.42it/s, loss=0.114, lr=5e-5]Steps:   6% 121/2000 [03:43<22:03,  1.42it/s, loss=0.114, lr=5e-5]\n",
            "Steps:   6% 122/2000 [03:43<21:51,  1.43it/s, loss=0.0947, lr=5e-5]Steps:   6% 122/2000 [03:43<21:51,  1.43it/s, loss=0.0947, lr=5e-5]\n",
            "Steps:   6% 123/2000 [03:44<21:44,  1.44it/s, loss=0.0866, lr=5e-5]Steps:   6% 123/2000 [03:44<21:44,  1.44it/s, loss=0.0866, lr=5e-5]\n",
            "Steps:   6% 124/2000 [03:45<21:39,  1.44it/s, loss=0.0824, lr=5e-5]Steps:   6% 124/2000 [03:45<21:39,  1.44it/s, loss=0.0824, lr=5e-5]\n",
            "Steps:   6% 125/2000 [03:45<21:36,  1.45it/s, loss=0.0863, lr=5e-5]Steps:   6% 125/2000 [03:45<21:36,  1.45it/s, loss=0.0863, lr=5e-5]\n",
            "Steps:   6% 126/2000 [03:46<21:50,  1.43it/s, loss=0.087, lr=5e-5]Steps:   6% 126/2000 [03:46<21:50,  1.43it/s, loss=0.087, lr=5e-5]\n",
            "Steps:   6% 126/2000 [03:46<21:50,  1.43it/s, loss=0.0539, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2629\n",
            "CPU Memory consumed at the end of the train (end-begin): -19\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2641\n",
            "Steps:   6% 127/2000 [03:48<31:04,  1.00it/s, loss=0.0539, lr=5e-5]Steps:   6% 127/2000 [03:48<31:04,  1.00it/s, loss=0.0539, lr=5e-5]\n",
            "Steps:   6% 128/2000 [03:49<28:13,  1.11it/s, loss=0.0906, lr=5e-5]Steps:   6% 128/2000 [03:49<28:13,  1.11it/s, loss=0.0906, lr=5e-5]\n",
            "Steps:   6% 129/2000 [03:49<26:41,  1.17it/s, loss=0.0359, lr=5e-5]Steps:   6% 129/2000 [03:49<26:41,  1.17it/s, loss=0.0359, lr=5e-5]\n",
            "Steps:   6% 130/2000 [03:50<25:02,  1.24it/s, loss=0.0898, lr=5e-5]Steps:   6% 130/2000 [03:50<25:02,  1.24it/s, loss=0.0898, lr=5e-5]\n",
            "Steps:   7% 131/2000 [03:51<23:56,  1.30it/s, loss=0.126, lr=5e-5]Steps:   7% 131/2000 [03:51<23:56,  1.30it/s, loss=0.126, lr=5e-5]\n",
            "Steps:   7% 132/2000 [03:51<23:13,  1.34it/s, loss=0.0945, lr=5e-5]Steps:   7% 132/2000 [03:51<23:13,  1.34it/s, loss=0.0945, lr=5e-5]\n",
            "Steps:   7% 133/2000 [03:52<22:39,  1.37it/s, loss=0.0904, lr=5e-5]Steps:   7% 133/2000 [03:52<22:39,  1.37it/s, loss=0.0904, lr=5e-5]\n",
            "Steps:   7% 134/2000 [03:53<22:16,  1.40it/s, loss=0.108, lr=5e-5]Steps:   7% 134/2000 [03:53<22:16,  1.40it/s, loss=0.108, lr=5e-5]\n",
            "Steps:   7% 135/2000 [03:53<22:01,  1.41it/s, loss=0.122, lr=5e-5]Steps:   7% 135/2000 [03:53<22:01,  1.41it/s, loss=0.122, lr=5e-5]\n",
            "Steps:   7% 136/2000 [03:54<21:48,  1.42it/s, loss=0.0586, lr=5e-5]Steps:   7% 136/2000 [03:54<21:48,  1.42it/s, loss=0.0586, lr=5e-5]\n",
            "Steps:   7% 137/2000 [03:55<21:41,  1.43it/s, loss=0.0805, lr=5e-5]Steps:   7% 137/2000 [03:55<21:41,  1.43it/s, loss=0.0805, lr=5e-5]\n",
            "Steps:   7% 138/2000 [03:55<21:34,  1.44it/s, loss=0.05, lr=5e-5]Steps:   7% 138/2000 [03:55<21:34,  1.44it/s, loss=0.05, lr=5e-5]\n",
            "Steps:   7% 139/2000 [03:56<21:32,  1.44it/s, loss=0.192, lr=5e-5]Steps:   7% 139/2000 [03:56<21:32,  1.44it/s, loss=0.192, lr=5e-5]\n",
            "Steps:   7% 140/2000 [03:57<21:34,  1.44it/s, loss=0.0852, lr=5e-5]Steps:   7% 140/2000 [03:57<21:34,  1.44it/s, loss=0.0852, lr=5e-5]\n",
            "Steps:   7% 141/2000 [03:58<21:39,  1.43it/s, loss=0.086, lr=5e-5]Steps:   7% 141/2000 [03:58<21:39,  1.43it/s, loss=0.086, lr=5e-5]\n",
            "Steps:   7% 142/2000 [03:58<21:34,  1.44it/s, loss=0.138, lr=5e-5]Steps:   7% 142/2000 [03:58<21:34,  1.44it/s, loss=0.138, lr=5e-5]\n",
            "Steps:   7% 143/2000 [03:59<21:30,  1.44it/s, loss=0.0896, lr=5e-5]Steps:   7% 143/2000 [03:59<21:30,  1.44it/s, loss=0.0896, lr=5e-5]\n",
            "Steps:   7% 144/2000 [04:00<21:29,  1.44it/s, loss=0.118, lr=5e-5]Steps:   7% 144/2000 [04:00<21:29,  1.44it/s, loss=0.118, lr=5e-5]\n",
            "Steps:   7% 145/2000 [04:00<21:24,  1.44it/s, loss=0.0811, lr=5e-5]Steps:   7% 145/2000 [04:00<21:24,  1.44it/s, loss=0.0811, lr=5e-5]\n",
            "Steps:   7% 146/2000 [04:01<21:24,  1.44it/s, loss=0.14, lr=5e-5]Steps:   7% 146/2000 [04:01<21:24,  1.44it/s, loss=0.14, lr=5e-5]\n",
            "Steps:   7% 147/2000 [04:02<22:13,  1.39it/s, loss=0.13, lr=5e-5]Steps:   7% 147/2000 [04:02<22:13,  1.39it/s, loss=0.13, lr=5e-5]\n",
            "Steps:   7% 147/2000 [04:02<22:13,  1.39it/s, loss=0.0972, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2610\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2622\n",
            "Steps:   7% 148/2000 [04:03<30:56,  1.00s/it, loss=0.0972, lr=5e-5]Steps:   7% 148/2000 [04:03<30:56,  1.00s/it, loss=0.0972, lr=5e-5]\n",
            "Steps:   7% 149/2000 [04:04<28:01,  1.10it/s, loss=0.0632, lr=5e-5]Steps:   7% 149/2000 [04:04<28:01,  1.10it/s, loss=0.0632, lr=5e-5]\n",
            "Steps:   8% 150/2000 [04:05<25:57,  1.19it/s, loss=0.123, lr=5e-5]Steps:   8% 150/2000 [04:05<25:57,  1.19it/s, loss=0.123, lr=5e-5]\n",
            "Steps:   8% 151/2000 [04:06<24:32,  1.26it/s, loss=0.0889, lr=5e-5]Steps:   8% 151/2000 [04:06<24:32,  1.26it/s, loss=0.0889, lr=5e-5]\n",
            "Steps:   8% 152/2000 [04:06<23:34,  1.31it/s, loss=0.0888, lr=5e-5]Steps:   8% 152/2000 [04:06<23:34,  1.31it/s, loss=0.0888, lr=5e-5]\n",
            "Steps:   8% 153/2000 [04:07<22:56,  1.34it/s, loss=0.0811, lr=5e-5]Steps:   8% 153/2000 [04:07<22:56,  1.34it/s, loss=0.0811, lr=5e-5]\n",
            "Steps:   8% 154/2000 [04:08<22:25,  1.37it/s, loss=0.183, lr=5e-5]Steps:   8% 154/2000 [04:08<22:25,  1.37it/s, loss=0.183, lr=5e-5]\n",
            "Steps:   8% 155/2000 [04:08<22:05,  1.39it/s, loss=0.0916, lr=5e-5]Steps:   8% 155/2000 [04:08<22:05,  1.39it/s, loss=0.0916, lr=5e-5]\n",
            "Steps:   8% 156/2000 [04:09<21:47,  1.41it/s, loss=0.1, lr=5e-5]Steps:   8% 156/2000 [04:09<21:47,  1.41it/s, loss=0.1, lr=5e-5]\n",
            "Steps:   8% 157/2000 [04:10<21:33,  1.42it/s, loss=0.0863, lr=5e-5]Steps:   8% 157/2000 [04:10<21:33,  1.42it/s, loss=0.0863, lr=5e-5]\n",
            "Steps:   8% 158/2000 [04:10<21:26,  1.43it/s, loss=0.113, lr=5e-5]Steps:   8% 158/2000 [04:10<21:26,  1.43it/s, loss=0.113, lr=5e-5]\n",
            "Steps:   8% 159/2000 [04:11<21:19,  1.44it/s, loss=0.0692, lr=5e-5]Steps:   8% 159/2000 [04:11<21:19,  1.44it/s, loss=0.0692, lr=5e-5]\n",
            "Steps:   8% 160/2000 [04:12<21:13,  1.44it/s, loss=0.11, lr=5e-5]Steps:   8% 160/2000 [04:12<21:13,  1.44it/s, loss=0.11, lr=5e-5]\n",
            "Steps:   8% 161/2000 [04:12<21:12,  1.45it/s, loss=0.0993, lr=5e-5]Steps:   8% 161/2000 [04:12<21:12,  1.45it/s, loss=0.0993, lr=5e-5]\n",
            "Steps:   8% 162/2000 [04:13<21:21,  1.43it/s, loss=0.0609, lr=5e-5]Steps:   8% 162/2000 [04:13<21:21,  1.43it/s, loss=0.0609, lr=5e-5]\n",
            "Steps:   8% 163/2000 [04:14<21:20,  1.43it/s, loss=0.141, lr=5e-5]Steps:   8% 163/2000 [04:14<21:20,  1.43it/s, loss=0.141, lr=5e-5]\n",
            "Steps:   8% 164/2000 [04:15<21:40,  1.41it/s, loss=0.148, lr=5e-5]Steps:   8% 164/2000 [04:15<21:40,  1.41it/s, loss=0.148, lr=5e-5]\n",
            "Steps:   8% 165/2000 [04:15<21:31,  1.42it/s, loss=0.0801, lr=5e-5]Steps:   8% 165/2000 [04:15<21:31,  1.42it/s, loss=0.0801, lr=5e-5]\n",
            "Steps:   8% 166/2000 [04:16<21:20,  1.43it/s, loss=0.19, lr=5e-5]Steps:   8% 166/2000 [04:16<21:20,  1.43it/s, loss=0.19, lr=5e-5]\n",
            "Steps:   8% 167/2000 [04:17<21:13,  1.44it/s, loss=0.157, lr=5e-5]Steps:   8% 167/2000 [04:17<21:13,  1.44it/s, loss=0.157, lr=5e-5]\n",
            "Steps:   8% 168/2000 [04:17<21:36,  1.41it/s, loss=0.085, lr=5e-5]Steps:   8% 168/2000 [04:17<21:36,  1.41it/s, loss=0.085, lr=5e-5]\n",
            "Steps:   8% 168/2000 [04:17<21:36,  1.41it/s, loss=0.058, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2610\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2622\n",
            "Steps:   8% 169/2000 [04:19<30:02,  1.02it/s, loss=0.058, lr=5e-5]Steps:   8% 169/2000 [04:19<30:02,  1.02it/s, loss=0.058, lr=5e-5]\n",
            "Steps:   8% 170/2000 [04:20<27:21,  1.11it/s, loss=0.074, lr=5e-5]Steps:   8% 170/2000 [04:20<27:21,  1.11it/s, loss=0.074, lr=5e-5]\n",
            "Steps:   9% 171/2000 [04:20<25:30,  1.19it/s, loss=0.0931, lr=5e-5]Steps:   9% 171/2000 [04:20<25:30,  1.19it/s, loss=0.0931, lr=5e-5]\n",
            "Steps:   9% 172/2000 [04:21<24:10,  1.26it/s, loss=0.149, lr=5e-5]Steps:   9% 172/2000 [04:21<24:10,  1.26it/s, loss=0.149, lr=5e-5]\n",
            "Steps:   9% 173/2000 [04:22<23:13,  1.31it/s, loss=0.0665, lr=5e-5]Steps:   9% 173/2000 [04:22<23:13,  1.31it/s, loss=0.0665, lr=5e-5]\n",
            "Steps:   9% 174/2000 [04:23<22:38,  1.34it/s, loss=0.047, lr=5e-5]Steps:   9% 174/2000 [04:23<22:38,  1.34it/s, loss=0.047, lr=5e-5]\n",
            "Steps:   9% 175/2000 [04:23<22:08,  1.37it/s, loss=0.105, lr=5e-5]Steps:   9% 175/2000 [04:23<22:08,  1.37it/s, loss=0.105, lr=5e-5]\n",
            "Steps:   9% 176/2000 [04:24<21:48,  1.39it/s, loss=0.0732, lr=5e-5]Steps:   9% 176/2000 [04:24<21:48,  1.39it/s, loss=0.0732, lr=5e-5]\n",
            "Steps:   9% 177/2000 [04:25<21:33,  1.41it/s, loss=0.161, lr=5e-5]Steps:   9% 177/2000 [04:25<21:33,  1.41it/s, loss=0.161, lr=5e-5]\n",
            "Steps:   9% 178/2000 [04:25<21:35,  1.41it/s, loss=0.108, lr=5e-5]Steps:   9% 178/2000 [04:25<21:35,  1.41it/s, loss=0.108, lr=5e-5]\n",
            "Steps:   9% 179/2000 [04:26<21:29,  1.41it/s, loss=0.124, lr=5e-5]Steps:   9% 179/2000 [04:26<21:29,  1.41it/s, loss=0.124, lr=5e-5]\n",
            "Steps:   9% 180/2000 [04:27<21:29,  1.41it/s, loss=0.0989, lr=5e-5]Steps:   9% 180/2000 [04:27<21:29,  1.41it/s, loss=0.0989, lr=5e-5]\n",
            "Steps:   9% 181/2000 [04:27<21:29,  1.41it/s, loss=0.085, lr=5e-5]Steps:   9% 181/2000 [04:27<21:29,  1.41it/s, loss=0.085, lr=5e-5]\n",
            "Steps:   9% 182/2000 [04:28<21:17,  1.42it/s, loss=0.199, lr=5e-5]Steps:   9% 182/2000 [04:28<21:17,  1.42it/s, loss=0.199, lr=5e-5]\n",
            "Steps:   9% 183/2000 [04:29<21:18,  1.42it/s, loss=0.0459, lr=5e-5]Steps:   9% 183/2000 [04:29<21:18,  1.42it/s, loss=0.0459, lr=5e-5]\n",
            "Steps:   9% 184/2000 [04:30<21:12,  1.43it/s, loss=0.0939, lr=5e-5]Steps:   9% 184/2000 [04:30<21:12,  1.43it/s, loss=0.0939, lr=5e-5]\n",
            "Steps:   9% 185/2000 [04:30<21:08,  1.43it/s, loss=0.0726, lr=5e-5]Steps:   9% 185/2000 [04:30<21:08,  1.43it/s, loss=0.0726, lr=5e-5]\n",
            "Steps:   9% 186/2000 [04:31<21:06,  1.43it/s, loss=0.0834, lr=5e-5]Steps:   9% 186/2000 [04:31<21:06,  1.43it/s, loss=0.0834, lr=5e-5]\n",
            "Steps:   9% 187/2000 [04:32<21:00,  1.44it/s, loss=0.293, lr=5e-5]Steps:   9% 187/2000 [04:32<21:00,  1.44it/s, loss=0.293, lr=5e-5]\n",
            "Steps:   9% 188/2000 [04:32<21:07,  1.43it/s, loss=0.0202, lr=5e-5]Steps:   9% 188/2000 [04:32<21:07,  1.43it/s, loss=0.0202, lr=5e-5]\n",
            "Steps:   9% 189/2000 [04:33<21:16,  1.42it/s, loss=0.0553, lr=5e-5]Steps:   9% 189/2000 [04:33<21:16,  1.42it/s, loss=0.0553, lr=5e-5]\n",
            "Steps:   9% 189/2000 [04:33<21:16,  1.42it/s, loss=0.0827, lr=5e-5]GPU Memory before entering the train : 3982\n",
            "GPU Memory consumed at the end of the train (end-begin): 0\n",
            "GPU Peak Memory consumed during the train (max-begin): 1542\n",
            "GPU Total Peak Memory consumed during the train (max): 5524\n",
            "CPU Memory before entering the train : 2610\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 12\n",
            "CPU Total Peak Memory consumed during the train (max): 2622\n",
            "Steps:  10% 190/2000 [04:35<29:43,  1.01it/s, loss=0.0827, lr=5e-5]Steps:  10% 190/2000 [04:35<29:43,  1.01it/s, loss=0.0827, lr=5e-5]\n",
            "Steps:  10% 191/2000 [04:35<27:03,  1.11it/s, loss=0.103, lr=5e-5]Steps:  10% 191/2000 [04:35<27:03,  1.11it/s, loss=0.103, lr=5e-5]\n",
            "Steps:  10% 192/2000 [04:36<25:11,  1.20it/s, loss=0.019, lr=5e-5]Steps:  10% 192/2000 [04:36<25:11,  1.20it/s, loss=0.019, lr=5e-5]\n",
            "Steps:  10% 193/2000 [04:37<23:51,  1.26it/s, loss=0.129, lr=5e-5]Steps:  10% 193/2000 [04:37<23:51,  1.26it/s, loss=0.129, lr=5e-5]\n",
            "Steps:  10% 194/2000 [04:37<22:55,  1.31it/s, loss=0.144, lr=5e-5]Steps:  10% 194/2000 [04:37<22:55,  1.31it/s, loss=0.144, lr=5e-5]\n",
            "Steps:  10% 195/2000 [04:38<22:17,  1.35it/s, loss=0.0675, lr=5e-5]Steps:  10% 195/2000 [04:38<22:17,  1.35it/s, loss=0.0675, lr=5e-5]\n",
            "Steps:  10% 196/2000 [04:39<21:49,  1.38it/s, loss=0.0858, lr=5e-5]Steps:  10% 196/2000 [04:39<21:49,  1.38it/s, loss=0.0858, lr=5e-5]\n",
            "Steps:  10% 197/2000 [04:39<21:33,  1.39it/s, loss=0.103, lr=5e-5]Steps:  10% 197/2000 [04:39<21:33,  1.39it/s, loss=0.103, lr=5e-5]\n",
            "Steps:  10% 198/2000 [04:40<21:19,  1.41it/s, loss=0.0807, lr=5e-5]Steps:  10% 198/2000 [04:40<21:19,  1.41it/s, loss=0.0807, lr=5e-5]\n",
            "Steps:  10% 199/2000 [04:41<21:19,  1.41it/s, loss=0.039, lr=5e-5]Steps:  10% 199/2000 [04:41<21:19,  1.41it/s, loss=0.039, lr=5e-5]\n",
            "Steps:  10% 200/2000 [04:42<21:06,  1.42it/s, loss=0.102, lr=5e-5]Steps:  10% 200/2000 [04:42<21:06,  1.42it/s, loss=0.102, lr=5e-5]\n",
            "Steps:  10% 201/2000 [04:42<20:58,  1.43it/s, loss=0.131, lr=5e-5]Steps:  10% 201/2000 [04:42<20:58,  1.43it/s, loss=0.131, lr=5e-5]\n",
            "Steps:  10% 201/2000 [04:42<20:58,  1.43it/s, loss=0.0621, lr=5e-5]02/16/2025 22:17:51 - INFO - __main__ - Running validation... \n",
            " Generating 10 images with prompt: Sticker with unusual dinosaursthe wearing a black top hat.\n",
            "{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  17% 1/6 [00:00<00:02,  1.77it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'force_upcast', 'latents_mean', 'use_quant_conv', 'mid_block_add_attention', 'use_post_quant_conv', 'shift_factor', 'latents_std', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  50% 3/6 [00:00<00:00,  5.40it/s]\u001b[A{'mid_block_only_cross_attention', 'addition_time_embed_dim', 'time_cond_proj_dim', 'dual_cross_attention', 'upcast_attention', 'num_attention_heads', 'attention_type', 'class_embed_type', 'only_cross_attention', 'time_embedding_dim', 'transformer_layers_per_block', 'dropout', 'conv_in_kernel', 'addition_embed_type', 'resnet_time_scale_shift', 'reverse_transformer_layers_per_block', 'class_embeddings_concat', 'mid_block_type', 'resnet_out_scale_factor', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'use_linear_projection', 'resnet_skip_time_act', 'num_class_embeds', 'timestep_post_act', 'encoder_hid_dim_type', 'conv_out_kernel', 'time_embedding_type', 'cross_attention_norm', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:01<00:00,  5.32it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 6/6 [00:01<00:00,  5.69it/s]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'use_exponential_sigmas', 'sample_max_value', 'solver_type', 'thresholding', 'lambda_min_clipped', 'solver_order', 'use_flow_sigmas', 'final_sigmas_type', 'prediction_type', 'dynamic_thresholding_ratio', 'use_karras_sigmas', 'euler_at_final', 'use_beta_sigmas', 'algorithm_type', 'use_lu_lambdas', 'rescale_betas_zero_snr', 'timestep_spacing', 'variance_type', 'flow_shift', 'lower_order_final'} was not found in config. Values will be initialized to default values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vx2HeT7N0tIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrUbsFto0tLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcZqzWyP0tO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWTm9w7-0tRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uk-vQIsy0tUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlX4t-Rb0tW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZpiNcCX0tZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3TE1RHv0tce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers import AutoTokenizer, PretrainedConfig\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "gYwkLkG_s_bF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DreamBoothDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset to prepare the instance images with the prompts for fine-tuning the model.\n",
        "    It pre-processes the images and tokenizes the prompts.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        instance_data_root,\n",
        "        tokenizer,\n",
        "        size=512,\n",
        "        center_crop=False,\n",
        "    ):\n",
        "        self.size = size\n",
        "        self.center_crop = center_crop\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.instance_data_root = Path(instance_data_root)\n",
        "        if not self.instance_data_root.exists():\n",
        "            raise ValueError(\"Instance images root doesn't exist.\")\n",
        "\n",
        "        image_extensions = [\".jpg\", \".jpeg\", \".png\", \".webp\"]\n",
        "        self.instance_images_path = [\n",
        "            p for p in Path(instance_data_root).iterdir()\n",
        "            if p.suffix.lower() in image_extensions\n",
        "            # and (p.with_suffix(\".txt\")).exists()\n",
        "        ]\n",
        "        self.num_instance_images = len(self.instance_images_path)\n",
        "        self._length = self.num_instance_images\n",
        "\n",
        "        # Load unique prompts from corresponding .txt files\n",
        "        prompts = pd.read_csv(instance_data_root + '/train.csv', index_col=['Unnamed: 0'])\n",
        "        self.instance_prompts = prompts['prompt'].to_list()\n",
        "\n",
        "        self.image_transforms = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.CenterCrop(size) if center_crop else transforms.RandomCrop(size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.5], [0.5]),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = {}\n",
        "        instance_image = Image.open(self.instance_images_path[index % self.num_instance_images])\n",
        "        if not instance_image.mode == \"RGB\":\n",
        "            instance_image = instance_image.convert(\"RGB\")\n",
        "        example[\"instance_images\"] = self.image_transforms(instance_image)\n",
        "\n",
        "        # Get the corresponding unique prompt\n",
        "        instance_prompt = self.instance_prompts[index % self.num_instance_images]\n",
        "        example[\"instance_prompt_ids\"] = self.tokenizer(\n",
        "            instance_prompt,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.tokenizer.model_max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        ).input_ids\n",
        "\n",
        "        return example\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "    input_ids = [example[\"instance_prompt_ids\"] for example in examples]\n",
        "    pixel_values = [example[\"instance_images\"] for example in examples]\n",
        "\n",
        "    pixel_values = torch.stack(pixel_values)\n",
        "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "\n",
        "    batch = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"pixel_values\": pixel_values,\n",
        "    }\n",
        "    return batch\n",
        "\n",
        "\n",
        "class PromptDataset(Dataset):\n",
        "    \"A simple dataset to prepare the prompts to generate class images on multiple GPUs.\"\n",
        "\n",
        "    def __init__(self, prompt, num_samples):\n",
        "        self.prompt = prompt\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = {}\n",
        "        example[\"prompt\"] = self.prompt\n",
        "        example[\"index\"] = index\n",
        "        return example\n"
      ],
      "metadata": {
        "id": "aICRL096s1Za"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instance_data_dir = '/content/drive/MyDrive/dino'\n",
        "tokenizer = tokenizer = AutoTokenizer.from_pretrained(\n",
        "            \"CompVis/stable-diffusion-v1-4\",\n",
        "            subfolder=\"tokenizer\",\n",
        "            # revision=revision,\n",
        "            use_fast=False,\n",
        "        )"
      ],
      "metadata": {
        "id": "UR1A4FWAtIxc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DreamBoothDataset(\n",
        "        instance_data_root=instance_data_dir,\n",
        "        tokenizer=tokenizer,\n",
        "        size=512,\n",
        "        # center_crop=args.center_crop,\n",
        "    )\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=1,\n",
        "    )"
      ],
      "metadata": {
        "id": "zuPFt-Oqshhk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        image_extensions = [\".jpg\", \".jpeg\", \".png\", \".webp\"]\n",
        "        instance_images_path = [\n",
        "            p for p in Path(instance_data_dir).iterdir()\n",
        "            if p.suffix.lower() in image_extensions\n",
        "            # and (p.with_suffix(\".txt\")).exists()\n",
        "        ]"
      ],
      "metadata": {
        "id": "PxlTv1CVw6V4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi5DKZrxxgdp",
        "outputId": "71a0f50d-d3cf-4648-9afa-3ef1a791c388"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}